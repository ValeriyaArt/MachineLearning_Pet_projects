{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"},"colab":{"name":"K3443_Artamonova_Text_processing_webinar.ipynb","provenance":[{"file_id":"1qNXv_GzDzMxqhzu-N2S2grEhkKHwwoRy","timestamp":1604999575049},{"file_id":"1SOx8vThNzVFZR_zaUlIZ56WxGNaVJ1hk","timestamp":1604754473954},{"file_id":"1XUT-Qa-VLIAMmHbt6pe3AdzDLSyaFoWv","timestamp":1604677054518},{"file_id":"1UpsFM_rY1G1r2EBkqj-A-3wpk1l_Ambe","timestamp":1596006394187},{"file_id":"1TtILmuSoWXOYmbTIAQmGaScvuHGWvpsI","timestamp":1595563808854},{"file_id":"1EdBdyqxLu-WiLmriWNwYl5Ct33JYcEG2","timestamp":1582113683695},{"file_id":"10_Aehfbxgr3fxXPgI1gM5BTU8yOy-Z4U","timestamp":1579514615233}],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"kz1hqb2oWg96"},"source":["# Инструменты для работы с текстом"]},{"cell_type":"markdown","metadata":{"id":"iXhKw6r2Wg97"},"source":["Анализ текстовых данных - это отдельное направление, здесь будет совсем небольшое введение.\n","С текстовыми данными можно решать как задачи обучения с учителем (классификация текстов), так и задачу обучения без учителя (кластеризация).\n","\n","Предобработка текста\n","\n","Первый шаг любой аналитики – получение данных. Предположим, что данные представляются собой набор текстов. Все известные нам алгоритмы работают не в текстами, а с объектами, которые описываются вектором признаков (чаще всего численных, категориальные мы умеем преобразовывать). Что делать, если наши объекты - это текст? \n","\n","Следующая после получения данных задача: предобработка. Основная цель предобработки: преобразовать текстовые данные в удобный для построения модели вид.\n","\n","Базовые шаги предобработки:\n","1. токенизация\n","2. приведение к нижнему регистру\n","3. удаление стоп-слов\n","4. удаление пунктуации\n","5. фильтрация по частоте/длине/соответствию регулярному выражению\n","6. лемматизация или стемминг\n","7. векторизация (эмбеддинг)\n","\n","Чаще всего применяются все эти шаги, но в разных задачах какие-то могут опускаться, поскольку приводят к потере информации"]},{"cell_type":"code","metadata":{"id":"IX-AeH8RWg9-"},"source":["import pandas as pd\n","import numpy as np\n","\n","from sklearn.metrics import * \n","from sklearn.model_selection import train_test_split "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Zpq4QOU5Wg-H"},"source":["* Сейчас мы попробуем получить преобразование предложений в численный вектор, с которым может работать стандартный алгоритм машинного обучения. \n","* Для этого нам понадобится познакомиться с понятием n-gram - самых мелких элементов предложения, с которыми можно работать. \n","* Подсчитав количество этих n-грам в предложениях, мы получим искомые численные представления."]},{"cell_type":"markdown","metadata":{"id":"i_7DyyXRWg-K"},"source":["## n-граммы\n","\n","Самые мелкие структуры языка, с которыми мы работаем, называются **n-граммами**.\n","У n-граммы есть параметр n - количество слов, которые попадают в такое представление текста.\n","* Если n = 1 - то мы смотрим на то, сколько раз каждое слово встретилось в тексте. Получаем _униграммы_\n","* Если n = 2 - то мы смотрим на то, сколько раз каждая пара подряд идущих слов, встретилась в тексте. Получаем _биграммы_"]},{"cell_type":"markdown","metadata":{"id":"quiUoyqNb3WA"},"source":["Функция для работы с n-граммами реализована в библиотке **nltk** (Natural Language ToolKit), импортируем эту функцию: "]},{"cell_type":"code","metadata":{"id":"hcrWxBzzWg-K"},"source":["from nltk import ngrams"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7ib-zYTvfQq5"},"source":["Прежде чем получать n-граммы, нужно разделить предложение на отдельные слова.  Для этого используем метод ```split()```."]},{"cell_type":"code","metadata":{"id":"wJ9aYx2UPK44"},"source":["sentence = 'Кто же победит на выборах в США: Трамп или Байден?'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A2Ql8Em4Wg-N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605361953254,"user_tz":-180,"elapsed":490,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"3660ce12-3b28-4bc3-b8cc-9a8dc74e65b9"},"source":["sentence_split = sentence.split()\n","sentence_split"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Кто',\n"," 'же',\n"," 'победит',\n"," 'на',\n"," 'выборах',\n"," 'в',\n"," 'США:',\n"," 'Трамп',\n"," 'или',\n"," 'Байден?']"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"GVIvz7OLN8yV"},"source":["Кажется, что нам тут мешают знаки препинания. Дайвайте от них избавимся. "]},{"cell_type":"code","metadata":{"id":"3i3IvCTPOIfB","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1605361957732,"user_tz":-180,"elapsed":871,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"cc938784-4c89-4b7b-cc1f-0b03bc6ece09"},"source":["import string\n","string.punctuation"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"NTiPD_lfPERo"},"source":["for ch in string.punctuation:\n","  sentence = sentence.replace(ch,\"\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4eY7anMcPxGB","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1605361960094,"user_tz":-180,"elapsed":748,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"db4db6aa-f89d-41cf-ee2d-ddbecdc829a4"},"source":["sentence"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Кто же победит на выборах в США Трамп или Байден'"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"AWvXpEdDP4kI"},"source":["sentence_split = sentence.split()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8uy1TrfAP-ui","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605361970844,"user_tz":-180,"elapsed":670,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"54892756-dd9b-4468-d0c4-ed3090bd590d"},"source":["sentence_split"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Кто', 'же', 'победит', 'на', 'выборах', 'в', 'США', 'Трамп', 'или', 'Байден']"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"d6V5P2Jcc4Oy"},"source":["Чтобы получить n-грамму для такой последовательности, используем функцию ```ngrams()```. \n","\n","На вход передается два параметра:\n","* лист с разделенным на отдельные слова предложением (у нас он хранится в переменной ```sent```);\n","* параметр n, определяющий, какой тип n-грамм мы хотим получить.\n","\n","\n","Чтобы полученный объект отобразить, делаем из него ```list```. "]},{"cell_type":"code","metadata":{"id":"F9oqpykUc5e9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605361976939,"user_tz":-180,"elapsed":1412,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"378ecc92-36c6-4d98-dcb1-b2deffb986ad"},"source":["list(ngrams(sentence_split, 1)) # униграммы"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('Кто',),\n"," ('же',),\n"," ('победит',),\n"," ('на',),\n"," ('выборах',),\n"," ('в',),\n"," ('США',),\n"," ('Трамп',),\n"," ('или',),\n"," ('Байден',)]"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"GZKRhRlxfoj4"},"source":["Аналогично мы можем получить биграммы - для этого заменяем параметр **n** в функции **ngrams** с 1 на 2."]},{"cell_type":"code","metadata":{"id":"Bzl6t5dpWg-P","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605361983006,"user_tz":-180,"elapsed":714,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"62b316e3-82e4-4339-fdd1-053633b09c6c"},"source":["list(ngrams(sentence_split, 2)) # биграммы"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('Кто', 'же'),\n"," ('же', 'победит'),\n"," ('победит', 'на'),\n"," ('на', 'выборах'),\n"," ('выборах', 'в'),\n"," ('в', 'США'),\n"," ('США', 'Трамп'),\n"," ('Трамп', 'или'),\n"," ('или', 'Байден')]"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"nCkkFzWLWg-R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605361985235,"user_tz":-180,"elapsed":922,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"448d8faa-099f-44d7-dad1-a7cfa14b56dc"},"source":["list(ngrams(sentence_split, 3)) # триграммы"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('Кто', 'же', 'победит'),\n"," ('же', 'победит', 'на'),\n"," ('победит', 'на', 'выборах'),\n"," ('на', 'выборах', 'в'),\n"," ('выборах', 'в', 'США'),\n"," ('в', 'США', 'Трамп'),\n"," ('США', 'Трамп', 'или'),\n"," ('Трамп', 'или', 'Байден')]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"GygS6_fJWg-S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605361986932,"user_tz":-180,"elapsed":879,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"603c942b-3095-4176-976a-5c1fd4eb958b"},"source":["list(ngrams(sentence_split, 5)) # ... пентаграммы"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('Кто', 'же', 'победит', 'на', 'выборах'),\n"," ('же', 'победит', 'на', 'выборах', 'в'),\n"," ('победит', 'на', 'выборах', 'в', 'США'),\n"," ('на', 'выборах', 'в', 'США', 'Трамп'),\n"," ('выборах', 'в', 'США', 'Трамп', 'или'),\n"," ('в', 'США', 'Трамп', 'или', 'Байден')]"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"_JewKs4XU-so"},"source":["## Векторизаторы\n","\n","Векторизатор преобразует слово или набор слов в числовой вектор, понятный алгоритму машинного обучения, который привык работать с числовыми табличными данными.\n","\n","Ниже - пример преобразования слов в двумерных вектор, каждому слову соответствует точка на плоскости.\n","\n","<a href=\"https://drive.google.com/uc?id=1ukv-FTj0jeVdcgVlOaNBocUfNuYGGVZg\n","\" target=\"_blank\"><img src=\"https://drive.google.com/uc?id=1ukv-FTj0jeVdcgVlOaNBocUfNuYGGVZg\" \n","alt=\"IMAGE ALT TEXT HERE\" width=\"600\" border=\"0\" /></a>"]},{"cell_type":"markdown","metadata":{"id":"V5hiNv2eVAc-"},"source":["На начальном этапе нам будет достаточно тех инструментов, которые уже есть в библиотеке **sklearn**."]},{"cell_type":"code","metadata":{"id":"cPplZnxeVEBR"},"source":["from sklearn.tree import DecisionTreeClassifier # можно заменить на другой классификатор\n","from sklearn.naive_bayes import MultinomialNB # наивный байесовский классификатор\n","from sklearn.feature_extraction.text import CountVectorizer # модель \"мешка слов\", см. далее"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eBN16KYZWg-U"},"source":["Самый простой способ извлечь признаки из текстовых данных -- векторизаторы: `CountVectorizer` и `TfidfVectorizer`\n","\n","Объект `CountVectorizer` делает следующую вещь:\n","* строит для каждого документа (каждой пришедшей ему строки) вектор размерности `n`, где `n` -- количество слов или n-грам во всём корпусе\n","* заполняет каждый i-тый элемент количеством вхождений слова в данный документ\n","\n","<a href=\"https://drive.google.com/uc?id=1ukv-FTj0jeVdcgVlOaNBocUfNuYGGVZg\n","\" target=\"_blank\"><img src=\"https://drive.google.com/uc?id=1jHmkrGZTMawM46Yzxh243Ur1y5pYKzrl\" \n","alt=\"IMAGE ALT TEXT HERE\" width=\"600\" border=\"0\" /></a>"]},{"cell_type":"markdown","metadata":{"id":"oklbwY_vWg-X"},"source":["На рисунке пример векторизации для униграмм, но можно использовать любые n-граммы. Для этого у объекта ```CountVectorizer()``` есть параметр **ngram_range**, который отвечает за то, какие n-граммы мы используем в качестве признаов:<br/>\n","ngram_range=(1, 1) -- униграммы<br/>\n","ngram_range=(3, 3) -- триграммы<br/>\n","ngram_range=(1, 3) -- униграммы, биграммы и триграммы."]},{"cell_type":"markdown","metadata":{"id":"5KabRubaXhNb"},"source":["## Пример"]},{"cell_type":"markdown","metadata":{"id":"0EnHNZtbXlH0"},"source":["К сожалению, на русском языке всё ещё очень мало годных наборов данных. Набор данных нашёл тут: https://github.com/sismetanin/rureviews"]},{"cell_type":"code","metadata":{"id":"yX-0fRF3hzCy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605362022228,"user_tz":-180,"elapsed":4698,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"0206823d-540b-490d-bf7a-e0d489892a7e"},"source":["!pip install PyDrive"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: PyDrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n","Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (1.7.12)\n","Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n","Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (4.1.3)\n","Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.15.0)\n","Requirement already satisfied: httplib2<1dev,>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.17.4)\n","Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.17.2)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.1)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.4)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n","Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.6)\n","Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.8)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (50.3.2)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (4.1.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aYRCckjEh2--"},"source":["from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fBBer1ozh5mL"},"source":["auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bP_tPtQDiGCx"},"source":["downloaded = drive.CreateFile({'id':\"10ssjgZnecPWkAHY-FPfyN8nAUS88fHFl\"}) \n","downloaded.GetContentFile('women-clothing-accessories.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g6709r3nXwIu"},"source":["data = pd.read_csv('women-clothing-accessories.csv', sep='\\t', usecols=[0, 1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u894TFlsYq3o","colab":{"base_uri":"https://localhost:8080/","height":197},"executionInfo":{"status":"ok","timestamp":1605362256165,"user_tz":-180,"elapsed":1092,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"da5bbcce-c069-48e9-a35f-a7846616ebe2"},"source":["data.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>качество плохое пошив ужасный (горловина напер...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Товар отдали другому человеку, я не получила п...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Ужасная синтетика! Тонкая, ничего общего с пре...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>товар не пришел, продавец продлил защиту без м...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Кофточка голая синтетика, носить не возможно.</td>\n","      <td>negative</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              review sentiment\n","0  качество плохое пошив ужасный (горловина напер...  negative\n","1  Товар отдали другому человеку, я не получила п...  negative\n","2  Ужасная синтетика! Тонкая, ничего общего с пре...  negative\n","3  товар не пришел, продавец продлил защиту без м...  negative\n","4      Кофточка голая синтетика, носить не возможно.  negative"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"09aeAe4zvwCv","colab":{"base_uri":"https://localhost:8080/","height":347},"executionInfo":{"status":"ok","timestamp":1605362267117,"user_tz":-180,"elapsed":709,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"4991f8d6-f900-4c34-fd59-4f266eaeead6"},"source":["data.sample(10)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>42143</th>\n","      <td>посылка пришла быстро, по размеру все подошло,...</td>\n","      <td>neautral</td>\n","    </tr>\n","    <tr>\n","      <th>50140</th>\n","      <td>В жизни цвет не такой красивый как на фотограф...</td>\n","      <td>neautral</td>\n","    </tr>\n","    <tr>\n","      <th>50990</th>\n","      <td>Ждала два с половиной месяца, посылка так и не...</td>\n","      <td>neautral</td>\n","    </tr>\n","    <tr>\n","      <th>86472</th>\n","      <td>На фото кажется длиннее, пришла посылка быстро...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>68378</th>\n","      <td>Пришли в Воронеж через 2 недели. Качество супе...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>9515</th>\n","      <td>Качество ужасное! Говно!!! Цвет противно рыже ...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>47827</th>\n","      <td>Отличное боди!супер быстрая доставка на дом!но...</td>\n","      <td>neautral</td>\n","    </tr>\n","    <tr>\n","      <th>74211</th>\n","      <td>лосины супер, даже дырочек нигде не было. НО н...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>9856</th>\n","      <td>Товар так и не пришёл. Раза 3 продлевали защит...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>75002</th>\n","      <td>После первой носки катышки, цену свою оправдывают</td>\n","      <td>positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                  review sentiment\n","42143  посылка пришла быстро, по размеру все подошло,...  neautral\n","50140  В жизни цвет не такой красивый как на фотограф...  neautral\n","50990  Ждала два с половиной месяца, посылка так и не...  neautral\n","86472  На фото кажется длиннее, пришла посылка быстро...  positive\n","68378  Пришли в Воронеж через 2 недели. Качество супе...  positive\n","9515   Качество ужасное! Говно!!! Цвет противно рыже ...  negative\n","47827  Отличное боди!супер быстрая доставка на дом!но...  neautral\n","74211  лосины супер, даже дырочек нигде не было. НО н...  positive\n","9856   Товар так и не пришёл. Раза 3 продлевали защит...  negative\n","75002  После первой носки катышки, цену свою оправдывают  positive"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"DpWqBU3-ZL5F"},"source":["x_train, x_test, y_train, y_test = train_test_split(data.review, data.sentiment, train_size = 0.7)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fKB-qv_obPrD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605362273465,"user_tz":-180,"elapsed":1028,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"25b6129e-fe29-4962-aaae-f0fff3c0e27b"},"source":["data.sentiment.value_counts()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["neautral    30000\n","negative    30000\n","positive    30000\n","Name: sentiment, dtype: int64"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"QtowE76LbIrG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605362274999,"user_tz":-180,"elapsed":706,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"d175b550-bb3b-45d1-8032-f3061f1c08b8"},"source":["y_train.value_counts()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["negative    21020\n","positive    21014\n","neautral    20965\n","Name: sentiment, dtype: int64"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"muRPBnySwfih"},"source":["Инициализируем `CountVectorizer()`, указав в качестве признаков униграммы:"]},{"cell_type":"code","metadata":{"id":"SfavuPF9wZh_"},"source":["vectorizer = CountVectorizer(ngram_range=(1, 1))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FIxErQg4wm-H"},"source":["После инициализации _vectorizer_ можно обучить на наших данных. \n","\n","Для обучения используем обучающую выборку ```x_train```, но в отличие от классификатора мы используем метод ```fit_transform()```: сначала обучаем наш векторизатор, а потом сразу применяем его к нашему набору данных. Это похоже на то, как мы работали с one-hot-encoderом."]},{"cell_type":"code","metadata":{"id":"0iwq0gTww0Pw"},"source":["vectorized_x_train = vectorizer.fit_transform(x_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Scw-UGKrwysI"},"source":["Так как результат не зависит от порядка слов в текстах, то говорят, что такая модель представления текстов в виде векторов получается из *гипотезы представления текста как мешка слов*"]},{"cell_type":"markdown","metadata":{"id":"IXZEX-AxxDp4"},"source":["В `vectorizer.vocabulary_` лежит словарь, отображение слов в их индексы:"]},{"cell_type":"code","metadata":{"id":"gRohdVRSxJIa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605362321045,"user_tz":-180,"elapsed":807,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"06a2e296-9393-4d4c-f9cb-37d216a64f05"},"source":["list(vectorizer.vocabulary_.items())[:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('шапка', 43784),\n"," ('супер', 39052),\n"," ('мех', 18734),\n"," ('натуральный', 20399),\n"," ('пумпон', 33113),\n"," ('пышный', 33317),\n"," ('ткань', 39852),\n"," ('голая', 9279),\n"," ('синтетика', 36466),\n"," ('продавец', 31967)]"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"BQCbnAk4wS_K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605362325868,"user_tz":-180,"elapsed":839,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"080be189-b196-4a9c-9b6f-dc63fcbc5673"},"source":["vectorized_x_train.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(62999, 44764)"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"CKFQVUZ11K47","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605362331127,"user_tz":-180,"elapsed":669,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"ea2cd52f-c8d1-46af-ae73-fba47d2f78b5"},"source":["x_train.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(62999,)"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"markdown","metadata":{"id":"gXAcWenlxQfc"},"source":["Так как теперь у нас есть **численное представление** и набор входных признаков, то мы можем обучить нашу модель"]},{"cell_type":"code","metadata":{"id":"icUoj9EexWcs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605362380222,"user_tz":-180,"elapsed":45989,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"dfd17d35-dc52-4640-f191-b46f298962bc"},"source":["clf = DecisionTreeClassifier()\n","clf.fit(vectorized_x_train, y_train)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n","                       max_depth=None, max_features=None, max_leaf_nodes=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=1, min_samples_split=2,\n","                       min_weight_fraction_leaf=0.0, presort='deprecated',\n","                       random_state=None, splitter='best')"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"Hf9V0s6jI1l2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605362621056,"user_tz":-180,"elapsed":1302,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"be9f21be-1dbd-4940-d4d1-c752e6472b77"},"source":["clf2 = MultinomialNB()\n","clf2.fit(vectorized_x_train, y_train)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"markdown","metadata":{"id":"jM85715BxfIx"},"source":["С тестовыми данными нужно проделать то же самое, что и с данными для обучения: сделать из текстов вектора, которые можно передавать в классификатор для прогноза класса объекта. \n","\n","У нас уже есть обученный векторизатор ```vectorizer```, поэтому используем метод ```transform()``` (просто применить его), а не ```fit_transform``` (обучить и применить)."]},{"cell_type":"code","metadata":{"id":"zWX6X7UHxjkj"},"source":["vectorized_x_test = vectorizer.transform(x_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SzvSUzEcxqMo"},"source":["Как раньше, для получения прогноза у обученного классификатора используем метод ```predict()```.\n","\n","С помощью функции ```classification_report()```, которая считает сразу несколько метрик качества классификации, посмотрим на то, насколько хорошо мы предсказываем положительную или отрицательную тональность твита ."]},{"cell_type":"code","metadata":{"id":"V7gssLYYxwkK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605362641472,"user_tz":-180,"elapsed":1374,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"f553ab8a-c637-4b32-9869-8f7e9bae8464"},"source":["pred = clf.predict(vectorized_x_test)\n","print(classification_report(y_test, pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","    neautral       0.52      0.54      0.53      9035\n","    negative       0.63      0.62      0.63      8980\n","    positive       0.76      0.75      0.75      8986\n","\n","    accuracy                           0.63     27001\n","   macro avg       0.64      0.63      0.63     27001\n","weighted avg       0.64      0.63      0.63     27001\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PvtntoJ0JNoK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605362650739,"user_tz":-180,"elapsed":1150,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"2e8ace92-3521-4a85-d8ce-6ebcdd7802b2"},"source":["pred2 = clf2.predict(vectorized_x_test)\n","print(classification_report(y_test, pred2))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","    neautral       0.59      0.66      0.62      9035\n","    negative       0.72      0.63      0.67      8980\n","    positive       0.84      0.84      0.84      8986\n","\n","    accuracy                           0.71     27001\n","   macro avg       0.72      0.71      0.71     27001\n","weighted avg       0.72      0.71      0.71     27001\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"seQ_QrKmJWoF"},"source":["Итак, наивный байесовский классификатор легко побил дерево решений. Дальше работаем с ним."]},{"cell_type":"markdown","metadata":{"id":"c6qcO2BceNsv"},"source":["### Отступление: F-мера"]},{"cell_type":"markdown","metadata":{"id":"z_qn9NrqeW6w"},"source":["Прошлый раз мы разобрали метрики качества классификации, которые выводятся из матрицы ошибок (confision matrix). \n","\n","**Полнота** (Sensitivity, True Positive Rate, Recall, Hit Rate) отражает какой процент объектов положительного класса мы правильно классифицировали.\n","\n","**Точность** (Precision, Positive Predictive Value) отражает какой процент положительных объектов (т.е. тех, что мы считаем положительными) правильно классифицирован. (Не путать с Accuracy!)\n","\n","Легко построить алгоритм со 100%-й полнотой: он все объекты относит к классу 1, но при этом точность может быть очень низкой. Нетрудно построить алгоритм с близкой к 100% точностью: он относит к классу 1 только те объекты, в которых уверен, при этом полнота может быть низкая.\n","\n","**F1-мера** (F1 score) является средним гармоническим точности и полноты, максимизация этого функционала приводит к одновременной максимизации этих двух «ортогональных критериев»\n","\n","$$F_1 = \\frac{2}{\\mathrm{recall}^{-1} + \\mathrm{precision}^{-1}} = 2 \\cdot \\frac{\\mathrm{precision} \\cdot \\mathrm{recall}}{\\mathrm{precision} + \\mathrm{recall}} = \\frac{\\mathrm{tp}}{\\mathrm{tp} + \\frac12 (\\mathrm{fp} + \\mathrm{fn}) } $$\n","\n","Также рассматривают весовое среднее гармоническое точности и полноты –  $F_\\beta$-меру:\n","\n","$$F_\\beta = (1 + \\beta^2) \\cdot \\frac{\\mathrm{precision} \\cdot \\mathrm{recall}}{(\\beta^2 \\cdot \\mathrm{precision}) + \\mathrm{recall}} = \\frac {(1 + \\beta^2) \\cdot \\mathrm{tp} }{(1 + \\beta^2) \\cdot \\mathrm{tp} + \\beta^2 \\cdot \\mathrm{fn} + \\mathrm{fp}}\\,$$\n","\n","Изменение $\\beta$ позволяет делать один из критериев (точность или полноту) важнее при оптимизации."]},{"cell_type":"markdown","metadata":{"id":"5yiLk1P_xYQ2"},"source":["## Биграммы"]},{"cell_type":"markdown","metadata":{"id":"mjy5ZPmwWg-j"},"source":["Попробуем сделать то же самое, используя в качестве признаков униграммы и биграммы:"]},{"cell_type":"code","metadata":{"id":"JKeS-Vmv13SE"},"source":["# инициализируем векторайзер \n","bigram_vectorizer = CountVectorizer(ngram_range=(1, 2))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hmQHqUpRWg-k"},"source":["# обучаем его и сразу применяем к x_train\n","bigram_vectorized_x_train = bigram_vectorizer.fit_transform(x_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PfG5x9i91_n4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605362685951,"user_tz":-180,"elapsed":739,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"9e6e61ea-8aff-4516-824f-0d79c47b60e5"},"source":["# инициализируем и обучаем классификатор\n","clf = MultinomialNB()\n","clf.fit(bigram_vectorized_x_train, y_train)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"twUcp7eU2E-9"},"source":["# применяем обученный векторизатор к тестовым данным\n","bigram_vectorized_x_test = bigram_vectorizer.transform(x_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sPsfMX7i2H1j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605362700786,"user_tz":-180,"elapsed":1241,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"8d7899e4-80a0-4069-86de-e1c9e4a45011"},"source":["# получаем предсказания и выводим информацию о качестве\n","pred = clf.predict(bigram_vectorized_x_test)\n","print(classification_report(y_test, pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","    neautral       0.61      0.67      0.64      9035\n","    negative       0.72      0.66      0.69      8980\n","    positive       0.87      0.85      0.86      8986\n","\n","    accuracy                           0.73     27001\n","   macro avg       0.73      0.73      0.73     27001\n","weighted avg       0.73      0.73      0.73     27001\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MonLW7AyWg-m"},"source":["У меня получилось повысить точность на пару процентов по сравнению с униграммами"]},{"cell_type":"code","metadata":{"id":"cdwrMRN93D31","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605362714497,"user_tz":-180,"elapsed":760,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"8d742772-1511-4832-9b79-26e6cb496a7b"},"source":["bigram_vectorized_x_train.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(62999, 462729)"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"markdown","metadata":{"id":"ZHzVwaMF3LPY"},"source":["\"Признаков\" объектов стало на порядок больше."]},{"cell_type":"markdown","metadata":{"id":"D39SSh0zWg-r"},"source":["## Токенизация\n","\n","Токенизировать - значит, поделить текст на части: слова, ключевые слова, фразы, символы и т.д., иными словами **токены**.\n","\n","Самый наивный способ токенизировать текст - разделить с помощью функции `split()`. Но `split` упускает очень много всего, например, не отделяет пунктуацию от слов. Кроме этого, есть ещё много менее тривиальных проблем, поэтому лучше использовать готовые токенизаторы."]},{"cell_type":"code","metadata":{"id":"hoSe08N2Wg-r"},"source":["import nltk # уже знакомая нам библиотека nltk\n","from nltk.tokenize import word_tokenize # готовый токенизатор библиотеки nltk"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DiDt3L8Y8god"},"source":["Чтобы использовать токенизатор ```word_tokenize```, нужно сначала скачать данные для nltk о пунктуации и стоп-словах."]},{"cell_type":"code","metadata":{"id":"gPH3yMcumsdd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605362734955,"user_tz":-180,"elapsed":1265,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"e84f123b-e972-4d59-a873-3255eecc0ff0"},"source":["nltk.download('stopwords')\n","nltk.download('punkt')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"markdown","metadata":{"id":"3NfDb8D_9DqD"},"source":["Применим токенизацию:"]},{"cell_type":"code","metadata":{"id":"zrJDGpgYWg-4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605362744365,"user_tz":-180,"elapsed":830,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"19064d37-fe0c-41f1-e6a5-985d93382dd8"},"source":["sentence = 'Кто же победит на выборах в США: Трамп или Байден?'\n","word_tokenize(sentence)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Кто',\n"," 'же',\n"," 'победит',\n"," 'на',\n"," 'выборах',\n"," 'в',\n"," 'США',\n"," ':',\n"," 'Трамп',\n"," 'или',\n"," 'Байден',\n"," '?']"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"markdown","metadata":{"id":"vxy7KGZI9bhK"},"source":["Сравните с использованием ```split()```:"]},{"cell_type":"code","metadata":{"id":"p52dIuSI9W6o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605362746936,"user_tz":-180,"elapsed":683,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"c0a78765-7102-47e0-95e1-dac1acf7f2d8"},"source":["sentence.split()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Кто',\n"," 'же',\n"," 'победит',\n"," 'на',\n"," 'выборах',\n"," 'в',\n"," 'США:',\n"," 'Трамп',\n"," 'или',\n"," 'Байден?']"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"markdown","metadata":{"id":"_702Dg5OWg-5"},"source":["В nltk вообще есть довольно много токенизаторов:"]},{"cell_type":"code","metadata":{"id":"Ps8oPYoTWg-6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605362754804,"user_tz":-180,"elapsed":867,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"92b6acae-7716-4612-89a1-83f9f5169008"},"source":["from nltk import tokenize\n","dir(tokenize)[:16]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['BlanklineTokenizer',\n"," 'LineTokenizer',\n"," 'MWETokenizer',\n"," 'PunktSentenceTokenizer',\n"," 'RegexpTokenizer',\n"," 'ReppTokenizer',\n"," 'SExprTokenizer',\n"," 'SpaceTokenizer',\n"," 'StanfordSegmenter',\n"," 'TabTokenizer',\n"," 'TextTilingTokenizer',\n"," 'ToktokTokenizer',\n"," 'TreebankWordTokenizer',\n"," 'TweetTokenizer',\n"," 'WhitespaceTokenizer',\n"," 'WordPunctTokenizer']"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"markdown","metadata":{"id":"lmnGCL5iWg-8"},"source":["Одни умеют выдавать индексы в строке для начала и конца каждого слова-токена:"]},{"cell_type":"code","metadata":{"id":"Jejj5X7QWg-8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605362759655,"user_tz":-180,"elapsed":830,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"717cf5bb-1da2-4ed1-bbb8-4c5e2692839e"},"source":["wh_tok = tokenize.WhitespaceTokenizer()\n","list(wh_tok.span_tokenize(sentence))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0, 3),\n"," (4, 6),\n"," (7, 14),\n"," (15, 17),\n"," (18, 25),\n"," (26, 27),\n"," (28, 32),\n"," (33, 38),\n"," (39, 42),\n"," (43, 50)]"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"markdown","metadata":{"id":"a-wf6A1EWg--"},"source":["Некторые токенизаторы ведут себя специфично:"]},{"cell_type":"code","metadata":{"id":"2REwpHGWWg-_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605362765624,"user_tz":-180,"elapsed":707,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"012095b6-b764-4b81-f6c7-4896e862ca1f"},"source":["tokenize.TreebankWordTokenizer().tokenize(\"don't stop me\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['do', \"n't\", 'stop', 'me']"]},"metadata":{"tags":[]},"execution_count":47}]},{"cell_type":"markdown","metadata":{"id":"Tckre90JWg_B"},"source":["А некоторые -- вообще не для текста на естественном языке:"]},{"cell_type":"code","metadata":{"id":"F1Ml3xtaWg_D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605362768290,"user_tz":-180,"elapsed":820,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"99067951-258f-496a-e48f-5cefcc1a1d00"},"source":["tokenize.SExprTokenizer().tokenize(\"(a (b c)) d e (f)\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['(a (b c))', 'd', 'e', '(f)']"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"markdown","metadata":{"id":"bM2kvAo0_b93"},"source":["**Правильный токенизатор подбирается исходя из требований задачи!**"]},{"cell_type":"markdown","metadata":{"id":"rhVrgkSaWg_K"},"source":["## Стоп-слова\n","\n","**Стоп-слова** - это слова, которые часто встречаются практически в любом тексте и ничего интересного не говорят о конретном документе. Для модели это просто шум. А шум нужно убирать. По аналогичной причине убирают и пунктуацию."]},{"cell_type":"code","metadata":{"id":"Ld-h6WKyWg_K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605362795671,"user_tz":-180,"elapsed":785,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"286139ab-0dcc-4369-e449-9b89bf9c34b2"},"source":["# импортируем стоп-слова из библиотеки nltk\n","from nltk.corpus import stopwords\n","\n","# посмотрим на стоп-слова для русского языка\n","print(stopwords.words('russian'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yHg5Z93iAyee"},"source":["noise = stopwords.words('russian')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t3gweXaWWg_P"},"source":["Теперь нужно обучать нашу модель с учетом новых знаний про токенизацию и стоп-слова. \n","\n","Для этого мы можем собрать новый векторизатор, передав ему на вход:\n","* какие n-граммы нам нужны, параметр **ngram_range**;\n","* какой токенизатор мы используем, параметр **tokenizer**;\n","* какие у нас стоп-слова, параметр **stop_words**."]},{"cell_type":"code","metadata":{"id":"fbXrVeRRuAxx"},"source":["# инициализируем умный векторайзер \n","smart_vectorizer = CountVectorizer(ngram_range=(1, 1), stop_words=noise)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BCM2Jy0448Mc"},"source":["# обучаем его и сразу применяем к x_train\n","smart_vectorized_x_train = smart_vectorizer.fit_transform(x_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UTiC4oUX5T__","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605362856735,"user_tz":-180,"elapsed":789,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"6ef62e38-d46e-4f23-ff12-872772e5b504"},"source":["smart_vectorized_x_train.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(62999, 44622)"]},"metadata":{"tags":[]},"execution_count":53}]},{"cell_type":"code","metadata":{"id":"7BztanE26o5Z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605362858525,"user_tz":-180,"elapsed":963,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"c2f6b023-f35e-4fe0-8836-8d0e1119b003"},"source":["list(smart_vectorizer.vocabulary_.items())[:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('шапка', 43648),\n"," ('супер', 38943),\n"," ('мех', 18676),\n"," ('натуральный', 20329),\n"," ('пумпон', 33013),\n"," ('пышный', 33217),\n"," ('ткань', 39737),\n"," ('голая', 9254),\n"," ('синтетика', 36359),\n"," ('продавец', 31867)]"]},"metadata":{"tags":[]},"execution_count":54}]},{"cell_type":"code","metadata":{"id":"7Nc6D-nwWg_P","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605362867649,"user_tz":-180,"elapsed":922,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"e7922b40-ba73-4010-860a-3dd4764d8c21"},"source":["# инициализируем и обучаем классификатор\n","clf = MultinomialNB()\n","clf.fit(smart_vectorized_x_train, y_train)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"]},"metadata":{"tags":[]},"execution_count":55}]},{"cell_type":"code","metadata":{"id":"OQ-P91PV5KST"},"source":["# применяем обученный векторайзер к тестовым данным\n","smart_vectorized_x_test = smart_vectorizer.transform(x_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8QJ3elF85MDB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605362872227,"user_tz":-180,"elapsed":1158,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"ecd86188-2e8f-44cb-86c5-07a740c65415"},"source":["# получаем предсказания и выводим информацию о качестве\n","pred = clf.predict(smart_vectorized_x_test)\n","print(classification_report(y_test, pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","    neautral       0.59      0.65      0.62      9035\n","    negative       0.71      0.62      0.67      8980\n","    positive       0.83      0.84      0.83      8986\n","\n","    accuracy                           0.71     27001\n","   macro avg       0.71      0.71      0.71     27001\n","weighted avg       0.71      0.71      0.71     27001\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DYWB1foQWg_T"},"source":["Получилось чуть хуже. \n","\n","Что ещё можно сделать?"]},{"cell_type":"markdown","metadata":{"id":"XsRf9T_SWg_U"},"source":["## Лемматизация\n","\n","**Лемматизация** – это сведение разных форм одного слова к начальной форме – **лемме**. Почему это хорошо?\n","* Во-первых, естественно рассматривать как отдельный признак каждое *слово*, а не каждую его отдельную форму.\n","* Во-вторых, некоторые стоп-слова стоят только в начальной форме, и без лематизации выкидываем мы только её.\n","\n","Для русского есть хороший лемматизатор pymorphy. \n","\n","Стемминг (англ. stemming — находить происхождение) — это процесс нахождения основы слова для заданного исходного слова. Основа слова не обязательно совпадает с морфологическим корнем слова. "]},{"cell_type":"markdown","metadata":{"id":"ylKZG2MwWg_f"},"source":["### [Pymorphy](http://pymorphy2.readthedocs.io/en/latest/)\n","Это модуль на питоне, довольно быстрый и с кучей функций."]},{"cell_type":"code","metadata":{"id":"JcYWYq4BzOon","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605453390389,"user_tz":-180,"elapsed":6329,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"7e4d5ed4-b468-46d5-8f28-a85a06537a99"},"source":["# устанавливаем pymorphy2\n","!pip install pymorphy2"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting pymorphy2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/57/b2ff2fae3376d4f3c697b9886b64a54b476e1a332c67eee9f88e7f1ae8c9/pymorphy2-0.9.1-py3-none-any.whl (55kB)\n","\r\u001b[K     |██████                          | 10kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 20kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 30kB 10.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 40kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 51kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 2.9MB/s \n","\u001b[?25hCollecting dawg-python>=0.7.1\n","  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n","Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n","Collecting pymorphy2-dicts-ru<3.0,>=2.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/79/bea0021eeb7eeefde22ef9e96badf174068a2dd20264b9a378f2be1cdd9e/pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2MB)\n","\u001b[K     |████████████████████████████████| 8.2MB 6.3MB/s \n","\u001b[?25hInstalling collected packages: dawg-python, pymorphy2-dicts-ru, pymorphy2\n","Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IqdT2pmRFn2F"},"source":["В pymorphy2 для морфологического анализа слов есть ```MorphAnalyzer()```:"]},{"cell_type":"code","metadata":{"id":"m4nRuUu2Wg_g"},"source":["from pymorphy2 import MorphAnalyzer\n","pymorphy2_analyzer = MorphAnalyzer()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Egd6KdqzWg_h"},"source":["pymorphy2 работает с отдельными словами. Если дать ему на вход предложение - он его просто не лемматизирует, т.к. не понимает:"]},{"cell_type":"code","metadata":{"id":"M6hdm1KBFx18","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605363969065,"user_tz":-180,"elapsed":766,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"85e21bb2-0f55-4d8d-ffe1-a7348b8d80d4"},"source":["sentence = 'Кто же победит на выборах в США: Трамп или Байден?'\n","sent = word_tokenize(sentence)\n","sent"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Кто',\n"," 'же',\n"," 'победит',\n"," 'на',\n"," 'выборах',\n"," 'в',\n"," 'США',\n"," ':',\n"," 'Трамп',\n"," 'или',\n"," 'Байден',\n"," '?']"]},"metadata":{"tags":[]},"execution_count":60}]},{"cell_type":"markdown","metadata":{"id":"Cr1C2beNF3vE"},"source":["Лемматизируем слово \"победит\" из предложения ```sentence``` с помощью метода ```parse()```:"]},{"cell_type":"code","metadata":{"id":"1Q3zNlPBWg_i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605363984396,"user_tz":-180,"elapsed":697,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"7dadae0f-5bfe-4177-b180-68f051dfe280"},"source":["ana = pymorphy2_analyzer.parse(sent[2])\n","ana"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Parse(word='победит', tag=OpencorporaTag('VERB,perf,tran sing,3per,futr,indc'), normal_form='победить', score=0.846153, methods_stack=((DictionaryAnalyzer(), 'победит', 2483, 9),)),\n"," Parse(word='победит', tag=OpencorporaTag('NOUN,inan,masc sing,nomn'), normal_form='победит', score=0.076923, methods_stack=((DictionaryAnalyzer(), 'победит', 34, 0),)),\n"," Parse(word='победит', tag=OpencorporaTag('NOUN,inan,masc sing,accs'), normal_form='победит', score=0.076923, methods_stack=((DictionaryAnalyzer(), 'победит', 34, 3),))]"]},"metadata":{"tags":[]},"execution_count":61}]},{"cell_type":"markdown","metadata":{"id":"m2O2BL4_GJzq"},"source":["Выведем его нормальную форму:"]},{"cell_type":"code","metadata":{"id":"7-zp0KZLWg_p","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1605363989222,"user_tz":-180,"elapsed":764,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"dd7f33ab-2725-44d5-ef09-4e5a68d8da05"},"source":["ana[0].normal_form"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'победить'"]},"metadata":{"tags":[]},"execution_count":62}]},{"cell_type":"markdown","metadata":{"id":"qUzhGLTxLIr9"},"source":["Нормализация предложения \"вижу три села\" может дать \"видеть тереть сесть\""]},{"cell_type":"code","metadata":{"id":"ldFCYxXuLL4p"},"source":["sent2 = word_tokenize('вижу три села')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oKRiNng-LfoP","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1605364002464,"user_tz":-180,"elapsed":850,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"caf38859-1920-4fc7-d9dc-bafaf762319d"},"source":["ana2 = pymorphy2_analyzer.parse(sent2[2])\n","ana2[0].normal_form"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'село'"]},"metadata":{"tags":[]},"execution_count":64}]},{"cell_type":"markdown","metadata":{"id":"VlWxW3e9Wg-m"},"source":["## TF-IDF векторизация"]},{"cell_type":"markdown","metadata":{"id":"u7hCxZRtWg-m"},"source":["`TfidfVectorizer` делает то же, что и `CountVectorizer`, но в качестве значений выдает **tf-idf** каждого слова.\n","\n","Как считается tf-idf:\n","\n","**TF (term frequency)** – относительная частотность слова в документе:\n","$$ TF(t,d) = \\frac{n_{t}}{\\sum_k n_{k}} $$\n","\n","**IDF (inverse document frequency)** – обратная частота документов, в которых есть это слово:\n","$$ IDF(t, D) = \\mbox{log} \\frac{|D|}{|{d : t \\in d}|} $$\n","\n","Перемножаем их:\n","$$TFIDF(t, d, D) = TF(t,d) \\times IDF(i, D)$$\n","\n","Cмысл: если слово часто встречается в одном документе, но в целом по корпусу встречается в небольшом \n","количестве документов, у него высокий TF-IDF."]},{"cell_type":"code","metadata":{"id":"Fv7DfTkJWg-n"},"source":["from sklearn.feature_extraction.text import TfidfVectorizer"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"02f_zZm14PHM"},"source":["Действуем аналогично, как с ```CountVectorizer()```:"]},{"cell_type":"code","metadata":{"id":"JjF9m3EOQTBK"},"source":["# инициализируем векторизатор, в качестве переменных используем униграммы\n","tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VrTdCw_TDE9o"},"source":["# обучаем его и сразу применяем к x_train\n","tfidf_vectorized_x_train = tfidf_vectorizer.fit_transform(x_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JPacf_DKDP7M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605364118301,"user_tz":-180,"elapsed":980,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"21da259b-ac2a-49e0-a3e6-e0010336be9c"},"source":["# инициализируем и обучаем классификатор\n","clf = MultinomialNB()\n","clf.fit(tfidf_vectorized_x_train, y_train)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"]},"metadata":{"tags":[]},"execution_count":68}]},{"cell_type":"code","metadata":{"id":"ljAO8NIPDSnK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605364121178,"user_tz":-180,"elapsed":1929,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"92f20fca-b37d-43dd-d85a-8e9580f28b19"},"source":["# применяем обученный векторизатор к тестовым данным\n","tfidf_vectorized_x_test = tfidf_vectorizer.transform(x_test)\n","\n","# получаем предсказания и выводим информацию о качестве\n","pred = clf.predict(tfidf_vectorized_x_test)\n","print(classification_report(y_test, pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","    neautral       0.59      0.66      0.63      9035\n","    negative       0.72      0.64      0.68      8980\n","    positive       0.84      0.84      0.84      8986\n","\n","    accuracy                           0.71     27001\n","   macro avg       0.72      0.71      0.71     27001\n","weighted avg       0.72      0.71      0.71     27001\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9hedBdcYWhAH"},"source":["Иногда пунктуация бывает и не шумом - главное отталкиваться от задачи. Что будет если вообще не убирать пунктуацию? На примере с твитами хорошо было бы видно, что пунктуация работает хорошо ))"]},{"cell_type":"code","metadata":{"id":"XhZMwsY5WhAI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605366615957,"user_tz":-180,"elapsed":30284,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"26513c17-66b8-434b-fcf3-65cdfdee86af"},"source":["# инициализируем умный векторайзер stop-words НЕ ИСПОЛЬЗУЕМ!\n","alternative_tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 1), \n","                                               tokenizer=word_tokenize)\n","\n","# обучаем его и сразу применяем к x_train\n","alternative_tfidf_vectorized_x_train = alternative_tfidf_vectorizer.fit_transform(x_train)\n","\n","# инициализируем и обучаем классификатор\n","clf = MultinomialNB()\n","clf.fit(alternative_tfidf_vectorized_x_train, y_train)\n","\n","# применяем обученный векторайзер к тестовым данным\n","alternative_tfidf_vectorized_x_test = alternative_tfidf_vectorizer.transform(x_test)\n","\n","# получаем предсказания и выводим информацию о качестве\n","pred = clf.predict(alternative_tfidf_vectorized_x_test)\n","print(classification_report(y_test, pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","    neautral       0.60      0.67      0.63      9035\n","    negative       0.72      0.65      0.68      8980\n","    positive       0.85      0.83      0.84      8986\n","\n","    accuracy                           0.72     27001\n","   macro avg       0.72      0.72      0.72     27001\n","weighted avg       0.72      0.72      0.72     27001\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FEQbCtidWhAP"},"source":["Посмотрим, как один из супер-значительных токенов справится с классификацией безо всякого машинного обучения:"]},{"cell_type":"code","metadata":{"id":"rhUG9qWuWhAQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605366831035,"user_tz":-180,"elapsed":1244,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"cc8bfecd-5d99-4026-f89b-47a10b5a44f4"},"source":["cool_token = 'плохо'\n","pred = ['positive' if cool_token in review else 'negative' for review in x_test]\n","print(classification_report(pred, y_test))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","    neautral       0.00      0.00      0.00         0\n","    negative       0.95      0.33      0.49     25817\n","    positive       0.02      0.14      0.03      1184\n","\n","    accuracy                           0.32     27001\n","   macro avg       0.32      0.16      0.17     27001\n","weighted avg       0.91      0.32      0.47     27001\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JrqW55jgWhAR"},"source":["## Символьные n-граммы\n","\n","В некоторых задачах в качестве признаков могут быть использщованы, n-граммы символов. Для этого необходимо установить в ```CountVectorizer()``` параметр ```analyzer = 'char'```, то есть анализировать символы."]},{"cell_type":"code","metadata":{"id":"o4lNhEmyWhAU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605366897624,"user_tz":-180,"elapsed":50691,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"cf978396-0121-4709-cddf-a0fe2849a31e"},"source":["# инициализируем векторайзер для символов\n","char_vectorizer = CountVectorizer(analyzer='char', ngram_range=(3, 6))\n","\n","# обучаем его и сразу применяем к x_train\n","char_vectorized_x_train = char_vectorizer.fit_transform(x_train)\n","\n","# инициализируем и обучаем классификатор\n","clf = MultinomialNB()\n","clf.fit(char_vectorized_x_train, y_train)\n","\n","# применяем обученный векторайзер к тестовым данным\n","char_vectorized_x_test = char_vectorizer.transform(x_test)\n","\n","# получаем предсказания и выводим информацию о качестве\n","pred = clf.predict(char_vectorized_x_test)\n","print(classification_report(y_test, pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","    neautral       0.59      0.71      0.64      9035\n","    negative       0.73      0.62      0.67      8980\n","    positive       0.87      0.83      0.85      8986\n","\n","    accuracy                           0.72     27001\n","   macro avg       0.73      0.72      0.72     27001\n","weighted avg       0.73      0.72      0.72     27001\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pLMMicsFWhAY"},"source":["Cимвольные n-граммы используются, например, для задачи определения языка. Ещё одна замечательная особенность признаков-символов - для них не нужна токенизация и лемматизация, можно использовать такой подход для языков, у которых нет готовых анализаторов."]},{"cell_type":"markdown","metadata":{"id":"bJox-LoonoPx"},"source":["## Задание 5\n","\n","Применим полученные выше навыки и решим задачу анализа тональности отзывов. (Те, кто предпочитает работать с английским языком, могут использовать набор данных `sms_spam`, он есть в папке `Data`).\n","\n","Нужно повторить весь пайплайн от сырых текстов до получения обученной модели.\n","\n","Обязательные шаги предобработки:\n","1. токенизация\n","2. приведение к нижнему регистру\n","3. удаление стоп-слов\n","4. лемматизация\n","5. векторизация (с настройкой гиперпараметров)\n","6. построение модели\n","7. оценка качества модели\n","\n","Обязательно использование векторайзеров:\n","1. мешок n-грамм (диапазон для n подбирайте самостоятельно, запрещено использовать только униграммы).\n","2. tf-idf ((диапазон для n подбирайте самостоятельно, также нужно подбирать параметры max_df, min_df, max_features)\n","3. символьные n-граммы (диапазон для n подбирайте самостоятельно)\n","\n","В качестве классификатора нужно использовать наивный байесовский классификатор. \n","\n","Для сравнения векторайзеров между собой используйте precision, recall, f1-score и accuracy. Для этого сформируйте датафрейм, в котором в строках будут разные векторайзеры, а в столбцах разные метрики качества, а в  ячейках будут значения этих метрик для соответсвующих векторайзеров."]},{"cell_type":"code","metadata":{"id":"HhCyvBhhKjov"},"source":["import pandas as pd\n","import numpy as np\n","import nltk\n","import string\n","\n","from sklearn.metrics import * \n","from sklearn.model_selection import train_test_split\n","from nltk import tokenize\n","from nltk import ngrams\n","from nltk.tokenize import word_tokenize # готовый токенизатор библиотеки nltk\n","# импортируем стоп-слова из библиотеки nltk\n","from nltk.corpus import stopwords"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yYZB1pvvLNNV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605455115268,"user_tz":-180,"elapsed":1122,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"f2ce0662-25e1-4b11-a0a5-b2bb3a7c2c34"},"source":["nltk.download('stopwords')\n","nltk.download('punkt')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"Itrf_hVE-ZIx"},"source":["from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TC9YNLi6-cgT"},"source":["auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HQy24yB3-mqm"},"source":["downloaded = drive.CreateFile({'id':\"10ssjgZnecPWkAHY-FPfyN8nAUS88fHFl\"}) \n","downloaded.GetContentFile('women-clothing-accessories.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7HrIVL0I-wRy","colab":{"base_uri":"https://localhost:8080/","height":407},"executionInfo":{"status":"ok","timestamp":1605459641571,"user_tz":-180,"elapsed":1461,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"0c203f85-24f9-4c6a-fd30-671feccc5df1"},"source":["data = pd.read_csv('women-clothing-accessories.csv', sep='\\t', usecols=[0, 1])\n","data"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>качество плохое пошив ужасный (горловина напер...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Товар отдали другому человеку, я не получила п...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Ужасная синтетика! Тонкая, ничего общего с пре...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>товар не пришел, продавец продлил защиту без м...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Кофточка голая синтетика, носить не возможно.</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>89995</th>\n","      <td>сделано достаточно хорошо. на ткани сделан рис...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>89996</th>\n","      <td>Накидка шикарная. Спасибо большое провдо линяе...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>89997</th>\n","      <td>спасибо большое ) продовца рекомендую.. заказа...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>89998</th>\n","      <td>Очень довольна заказом! Меньше месяца в РБ.  К...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>89999</th>\n","      <td>хорошая куртка. постороннего запаха нет. швы р...</td>\n","      <td>positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>90000 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                  review sentiment\n","0      качество плохое пошив ужасный (горловина напер...  negative\n","1      Товар отдали другому человеку, я не получила п...  negative\n","2      Ужасная синтетика! Тонкая, ничего общего с пре...  negative\n","3      товар не пришел, продавец продлил защиту без м...  negative\n","4          Кофточка голая синтетика, носить не возможно.  negative\n","...                                                  ...       ...\n","89995  сделано достаточно хорошо. на ткани сделан рис...  positive\n","89996  Накидка шикарная. Спасибо большое провдо линяе...  positive\n","89997  спасибо большое ) продовца рекомендую.. заказа...  positive\n","89998  Очень довольна заказом! Меньше месяца в РБ.  К...  positive\n","89999  хорошая куртка. постороннего запаха нет. швы р...  positive\n","\n","[90000 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"code","metadata":{"id":"K9wfr_v9AOg0","colab":{"base_uri":"https://localhost:8080/","height":407},"executionInfo":{"status":"ok","timestamp":1605459646465,"user_tz":-180,"elapsed":1399,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"f2e1033d-46e0-4176-e177-a61ad6b5636e"},"source":["# 2. ПРИВЕДЕНИЕ К НИЖНЕМУ РЕГИСТРУ\n","data['review'] = data.review.str.lower()\n","data"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>качество плохое пошив ужасный (горловина напер...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>товар отдали другому человеку, я не получила п...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ужасная синтетика! тонкая, ничего общего с пре...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>товар не пришел, продавец продлил защиту без м...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>кофточка голая синтетика, носить не возможно.</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>89995</th>\n","      <td>сделано достаточно хорошо. на ткани сделан рис...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>89996</th>\n","      <td>накидка шикарная. спасибо большое провдо линяе...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>89997</th>\n","      <td>спасибо большое ) продовца рекомендую.. заказа...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>89998</th>\n","      <td>очень довольна заказом! меньше месяца в рб.  к...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>89999</th>\n","      <td>хорошая куртка. постороннего запаха нет. швы р...</td>\n","      <td>positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>90000 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                  review sentiment\n","0      качество плохое пошив ужасный (горловина напер...  negative\n","1      товар отдали другому человеку, я не получила п...  negative\n","2      ужасная синтетика! тонкая, ничего общего с пре...  negative\n","3      товар не пришел, продавец продлил защиту без м...  negative\n","4          кофточка голая синтетика, носить не возможно.  negative\n","...                                                  ...       ...\n","89995  сделано достаточно хорошо. на ткани сделан рис...  positive\n","89996  накидка шикарная. спасибо большое провдо линяе...  positive\n","89997  спасибо большое ) продовца рекомендую.. заказа...  positive\n","89998  очень довольна заказом! меньше месяца в рб.  к...  positive\n","89999  хорошая куртка. постороннего запаха нет. швы р...  positive\n","\n","[90000 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"code","metadata":{"id":"WDBuS9lfAUik"},"source":["# 3. УДАЛЕНИЕ СТОП-СЛОВ\n","noise = stopwords.words('russian')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JGbRU07ffEWo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605454554688,"user_tz":-180,"elapsed":1010,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"1402520e-5dfe-48ba-a2b5-c0c034c224db"},"source":["import nltk\n","from nltk.tokenize import word_tokenize # готовый токенизатор библиотеки nltk\n","\n","nltk.download('wordnet')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"qesVLyo1i3SH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605455245491,"user_tz":-180,"elapsed":3422,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"77bf19a2-a46a-43f4-c57b-04a9bc8e5746"},"source":["!pip install pymorphy2"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.6/dist-packages (0.9.1)\n","Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (2.4.417127.4579844)\n","Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n","Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.7.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4zGIIOjWAbcP","colab":{"base_uri":"https://localhost:8080/","height":407},"executionInfo":{"status":"ok","timestamp":1605460069905,"user_tz":-180,"elapsed":371828,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"3faab340-0d6d-49d7-bf72-89075477d489"},"source":["# 1. ТОКЕНИЗАЦИЯ\n","\n","from nltk.tokenize import word_tokenize # готовый токенизатор библиотеки nltk\n","\n","# 4. ЛЕММАТИЗАЦИЯ\n","from pymorphy2 import MorphAnalyzer\n","pymorphy2_analyzer = MorphAnalyzer()\n","\n","def lemmatize_text(text):\n","    return [str(pymorphy2_analyzer.parse(w)[0].normal_form) for w in word_tokenize(text)]\n","\n","data['review'] = data.review.apply(lemmatize_text)\n","data"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[качество, плохой, пошив, ужасный, (, горловин...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[товар, отдать, другой, человек, ,, я, не, пол...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[ужасный, синтетик, !, тонкий, ,, ничего, общи...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[товар, не, прийти, ,, продавец, продлить, защ...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[кофточка, голый, синтетик, ,, носить, не, воз...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>89995</th>\n","      <td>[сделать, достаточно, хорошо, ., на, ткань, сд...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>89996</th>\n","      <td>[накидка, шикарный, ., спасибо, большой, провд...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>89997</th>\n","      <td>[спасибо, большой, ), продовца, рекомендую.., ...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>89998</th>\n","      <td>[очень, довольный, заказ, !, маленький, месяц,...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>89999</th>\n","      <td>[хороший, куртка, ., посторонний, запах, нет, ...</td>\n","      <td>positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>90000 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                  review sentiment\n","0      [качество, плохой, пошив, ужасный, (, горловин...  negative\n","1      [товар, отдать, другой, человек, ,, я, не, пол...  negative\n","2      [ужасный, синтетик, !, тонкий, ,, ничего, общи...  negative\n","3      [товар, не, прийти, ,, продавец, продлить, защ...  negative\n","4      [кофточка, голый, синтетик, ,, носить, не, воз...  negative\n","...                                                  ...       ...\n","89995  [сделать, достаточно, хорошо, ., на, ткань, сд...  positive\n","89996  [накидка, шикарный, ., спасибо, большой, провд...  positive\n","89997  [спасибо, большой, ), продовца, рекомендую.., ...  positive\n","89998  [очень, довольный, заказ, !, маленький, месяц,...  positive\n","89999  [хороший, куртка, ., посторонний, запах, нет, ...  positive\n","\n","[90000 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":55}]},{"cell_type":"code","metadata":{"id":"QJLHJhPWtYVe","colab":{"base_uri":"https://localhost:8080/","height":407},"executionInfo":{"status":"ok","timestamp":1605460515348,"user_tz":-180,"elapsed":910,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"f83cd871-9b86-492a-a92b-bac5cf80131c"},"source":["data['review'] = data['review'].astype(str)\n","data"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>['качество', 'плохой', 'пошив', 'ужасный', '('...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>['товар', 'отдать', 'другой', 'человек', ',', ...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>['ужасный', 'синтетик', '!', 'тонкий', ',', 'н...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>['товар', 'не', 'прийти', ',', 'продавец', 'пр...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>['кофточка', 'голый', 'синтетик', ',', 'носить...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>89995</th>\n","      <td>['сделать', 'достаточно', 'хорошо', '.', 'на',...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>89996</th>\n","      <td>['накидка', 'шикарный', '.', 'спасибо', 'больш...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>89997</th>\n","      <td>['спасибо', 'большой', ')', 'продовца', 'реком...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>89998</th>\n","      <td>['очень', 'довольный', 'заказ', '!', 'маленьки...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>89999</th>\n","      <td>['хороший', 'куртка', '.', 'посторонний', 'зап...</td>\n","      <td>positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>90000 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                  review sentiment\n","0      ['качество', 'плохой', 'пошив', 'ужасный', '('...  negative\n","1      ['товар', 'отдать', 'другой', 'человек', ',', ...  negative\n","2      ['ужасный', 'синтетик', '!', 'тонкий', ',', 'н...  negative\n","3      ['товар', 'не', 'прийти', ',', 'продавец', 'пр...  negative\n","4      ['кофточка', 'голый', 'синтетик', ',', 'носить...  negative\n","...                                                  ...       ...\n","89995  ['сделать', 'достаточно', 'хорошо', '.', 'на',...  positive\n","89996  ['накидка', 'шикарный', '.', 'спасибо', 'больш...  positive\n","89997  ['спасибо', 'большой', ')', 'продовца', 'реком...  positive\n","89998  ['очень', 'довольный', 'заказ', '!', 'маленьки...  positive\n","89999  ['хороший', 'куртка', '.', 'посторонний', 'зап...  positive\n","\n","[90000 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":66}]},{"cell_type":"code","metadata":{"id":"yT04ZNdPNdCN"},"source":["# разделяем выборку на обучающую и тестовую\n","x_train, x_test, y_train, y_test = train_test_split(data.review, data.sentiment, train_size = 0.7)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZxeHpyd0n41V","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605460541124,"user_tz":-180,"elapsed":1237,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"187da049-36c7-45ae-d54b-a49eff0e8ecd"},"source":["type(x_train)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["pandas.core.series.Series"]},"metadata":{"tags":[]},"execution_count":69}]},{"cell_type":"code","metadata":{"id":"mH6jXK_4AlUr"},"source":["# 5. ВЕКТОРИЗАЦИЯ (С НАСТРОЙКОЙ ГИПЕРПАРАМЕТРОВ)\n","# 5.1 мешок n-грамм\n","from sklearn.naive_bayes import MultinomialNB # наивный байесовский классификатор\n","from sklearn.feature_extraction.text import CountVectorizer # модель \"мешка слов\", см. далее\n","vectorizer = CountVectorizer(ngram_range=(1, 2), stop_words=noise)\n","# обучаем и сразу применяем к x_train\n","vectorized_x_train = vectorizer.fit_transform(x_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VjBGcqKNU8F6"},"source":["# 5.2 tf-idf \n","from sklearn.feature_extraction.text import TfidfVectorizer\n","tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 3), stop_words=noise)\n","# обучаем и сразу применяем к x_train\n","tfidf_vectorized_x_train = tfidf_vectorizer.fit_transform(x_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C1mhPU39U7tE"},"source":["# 5.3 символьные n-граммы\n","char_vectorizer = CountVectorizer(analyzer='char', ngram_range=(4, 6), stop_words=noise)\n","# обучаем и сразу применяем к x_train\n","char_vectorized_x_train = char_vectorizer.fit_transform(x_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C4A1ZhHVAngh"},"source":["# 6. ПОСТРОЕНИЕ МОДЕЛИ\n","# 6.1 мешок n-грамм\n","clf_ng = MultinomialNB()\n","clf_ng.fit(vectorized_x_train, y_train)\n","# применяем обученный векторизатор к тестовым данным\n","vectorized_x_test = vectorizer.transform(x_test)\n","pred_ng = clf_ng.predict(vectorized_x_test)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xS0dbL19VVQ4"},"source":["# 6.2 tf-idf \n","# инициализируем и обучаем классификатор\n","clf_tf = MultinomialNB()\n","clf_tf.fit(tfidf_vectorized_x_train, y_train)\n","# применяем обученный векторизатор к тестовым данным\n","tfidf_vectorized_x_test = tfidf_vectorizer.transform(x_test)\n","pred_tf = clf_tf.predict(tfidf_vectorized_x_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jCxTa974VU_w"},"source":["# 6.3 символьные n-граммы\n","# инициализируем и обучаем классификатор\n","clf_cng = MultinomialNB()\n","clf_cng.fit(char_vectorized_x_train, y_train)\n","\n","# применяем обученный векторайзер к тестовым данным\n","char_vectorized_x_test = char_vectorizer.transform(x_test)\n","pred_cng = clf_cng.predict(char_vectorized_x_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lq83rUStApI3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605461850849,"user_tz":-180,"elapsed":2062,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"f61bc026-9bca-413e-bcb6-6ab0d3776e3d"},"source":["# 7. ОЦЕНКА КАЧЕСТВА МОДЕЛИ\n","# 7.1 мешок n-грамм\n","print(classification_report(y_test, pred_ng))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","    neautral       0.60      0.65      0.63      8954\n","    negative       0.73      0.65      0.69      9071\n","    positive       0.83      0.86      0.84      8976\n","\n","    accuracy                           0.72     27001\n","   macro avg       0.72      0.72      0.72     27001\n","weighted avg       0.72      0.72      0.72     27001\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"spYjfpzgVWdr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605461738916,"user_tz":-180,"elapsed":1684,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"fc004d76-1e60-4738-bcc6-860d3c022519"},"source":["# 7.2 tf-idf \n","print(classification_report(y_test, pred_tf))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","    neautral       0.60      0.64      0.62      8954\n","    negative       0.74      0.65      0.69      9071\n","    positive       0.82      0.86      0.84      8976\n","\n","    accuracy                           0.72     27001\n","   macro avg       0.72      0.72      0.72     27001\n","weighted avg       0.72      0.72      0.72     27001\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7GHJsLmfVWRX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605462072843,"user_tz":-180,"elapsed":1156,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"7efc056d-925e-423a-f097-8fe4014a6913"},"source":["# 7.3 символьные n-граммы\n","print(classification_report(y_test, pred_cng))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","    neautral       0.58      0.71      0.64      8954\n","    negative       0.74      0.62      0.67      9071\n","    positive       0.86      0.82      0.84      8976\n","\n","    accuracy                           0.71     27001\n","   macro avg       0.73      0.72      0.72     27001\n","weighted avg       0.73      0.71      0.72     27001\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AAfMDLSxVwyE","colab":{"base_uri":"https://localhost:8080/","height":137},"executionInfo":{"status":"ok","timestamp":1605462081237,"user_tz":-180,"elapsed":2758,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"6c09df57-06b2-4ab2-b3ba-3f4cdd62957d"},"source":["# сравнение векторайзеров\n","ng_report = classification_report(y_test, pred_ng, output_dict=True)\n","tf_report = classification_report(y_test, pred_tf, output_dict=True)\n","cng_report = classification_report(y_test, pred_cng, output_dict=True)\n","\n","df = pd.DataFrame([['Мешок N-грамм',ng_report['weighted avg']['precision'], ng_report['weighted avg']['recall'],ng_report['weighted avg']['f1-score'], ng_report['accuracy']],\n","                  ['TF-IDF',tf_report['weighted avg']['precision'],tf_report['weighted avg']['recall'],tf_report['weighted avg']['f1-score'],tf_report['accuracy']],\n","                  ['Символьные N-граммы',cng_report['weighted avg']['precision'],cng_report['weighted avg']['recall'],cng_report['weighted avg']['f1-score'],cng_report['accuracy']]], \n","columns=['Векторайзер','Precision','Recall', 'F1-score', 'Accuracy'])\n","df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Векторайзер</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1-score</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Мешок N-грамм</td>\n","      <td>0.722521</td>\n","      <td>0.719936</td>\n","      <td>0.719998</td>\n","      <td>0.719936</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>TF-IDF</td>\n","      <td>0.720577</td>\n","      <td>0.719122</td>\n","      <td>0.718621</td>\n","      <td>0.719122</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Символьные N-граммы</td>\n","      <td>0.727561</td>\n","      <td>0.714677</td>\n","      <td>0.717116</td>\n","      <td>0.714677</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           Векторайзер  Precision    Recall  F1-score  Accuracy\n","0        Мешок N-грамм   0.722521  0.719936  0.719998  0.719936\n","1               TF-IDF   0.720577  0.719122  0.718621  0.719122\n","2  Символьные N-граммы   0.727561  0.714677  0.717116  0.714677"]},"metadata":{"tags":[]},"execution_count":136}]},{"cell_type":"markdown","metadata":{"id":"5QYTwyMtWhAZ"},"source":["## Бонус 1. Регулярные выражения\n","\n","Регулярные выражения - способ поиска и анализа строк. Например, можно понять, какие даты в наборе строк представлены в формате DD/MM/YYYY, а какие - в других форматах. \n","\n","Или бывает, например, что перед работой с текстом, надо почистить его от своеобразного мусора: упоминаний пользователей, url и так далее.\n","\n","Навык полезный, давайте в нём тоже потренируемся.\n","\n","Для работы с регулярными выражениями есть библиотека **re**"]},{"cell_type":"code","metadata":{"id":"VaUW5S4gWhAb"},"source":["import re"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D6aYh7Osl8xr"},"source":["В регулярных выражениях, кроме привычных символов-букв, есть специальные символы:\n","* **?а** - ноль или один символ **а**\n","* **+а** - один или более символов **а**\n","* **\\*а** - ноль или более символов **а** (не путать с +)\n","* **.** - любое количество любого символа\n","\n","Пример:\n","Выражению \\*a?b. соответствуют последовательности a, ab, abc, aa, aac НО НЕ abb!"]},{"cell_type":"markdown","metadata":{"id":"q7zOFFA3l_KQ"},"source":["Рассмотрим подробно несколько наиболее полезных функций:"]},{"cell_type":"markdown","metadata":{"id":"DbJrUpARWhAd"},"source":["### findall\n","возвращает список всех найденных непересекающихся совпадений.\n","\n","Регулярное выражение **ab+c.**: \n","* **a** - просто символ **a**\n","* **b+** - один или более символов **b**\n","* **c** - просто символ **c**\n","* **.** - любой символ\n"]},{"cell_type":"code","metadata":{"id":"2athHzKuWhAd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605055301006,"user_tz":-180,"elapsed":1331,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"11510207-31fa-45ba-dee3-0bdcb5e2a307"},"source":["result = re.findall('ab+c.', 'abcdefghijkabcabcxabc') \n","print(result)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['abcd', 'abca']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"A9FpIw5RWhAf"},"source":["Вопрос на внимательность: почему нет abcx?"]},{"cell_type":"markdown","metadata":{"id":"B5ttzoxEWhAg"},"source":["**Задание**: вернуть список первых двух букв каждого слова в строке, состоящей из нескольких слов."]},{"cell_type":"code","metadata":{"id":"7ZR2AEq3WhAg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605056266697,"user_tz":-180,"elapsed":1524,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"be415350-25a9-40ca-d672-838cd1145d22"},"source":["result = re.findall('\\b\\w\\w', 'If everything could ever be this real forever.') \n","print(result)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MI18l-l9WhAk"},"source":["### split\n","разделяет строку по заданному шаблону\n"]},{"cell_type":"code","metadata":{"id":"sVKdRoc1WhAl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605018912441,"user_tz":-180,"elapsed":1187,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"b37e89ee-edec-470c-cd07-45ab813b9c7d"},"source":["result = re.split(',', 'itsy, bitsy, teenie, weenie') \n","print(result)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['itsy', ' bitsy', ' teenie', ' weenie']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"10u5efuSWhAm"},"source":["можно указать максимальное количество разбиений"]},{"cell_type":"code","metadata":{"id":"9U9EQZMwWhAn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605018806533,"user_tz":-180,"elapsed":770,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"12552450-cc36-4735-d097-35e9626649b7"},"source":["result = re.split(',', 'itsy, bitsy, teenie, weenie', maxsplit=2) \n","print(result)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['itsy', ' bitsy', ' teenie, weenie']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0EMcMyflWhAp"},"source":["**Задание**: разбейте строку, состоящую из нескольких предложений, по точкам, но не более чем на 3 предложения."]},{"cell_type":"code","metadata":{"id":"dVgPSjEOWhAp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605055942110,"user_tz":-180,"elapsed":1108,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"39aecfdb-ee36-43c8-8508-c1d87f28df9c"},"source":["result = re.split('\\.', 'В классическом понимании полимат — это человек, обладающий обширными знаниями в разных областях. В эпоху Возрождения полиматия являлась частью идеи о совершенном человеке, который должен был быть одновременно ученым и художником, и при этом быть развитым физически. Леонардо да Винчи гордился своей способностью гнуть железные прутья примерно в той же степени, что Моной Лизой. Я был здоров, молод, весел, деньги у меня не переводились, заботы еще не успели завестись - я жил без оглядки, делал что хотел, процветал, одним словом. Мне тогда и в голову не приходило, что человек не растение и процветать ему долго нельзя. Молодость ест пряники золоченые, да и думает, что это-то и есть хлеб насущный; а придет время - и хлебца напросишься. Но толковать об этом не для чего.', maxsplit=2) \n","print(result)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['В классическом понимании полимат — это человек, обладающий обширными знаниями в разных областях', ' В эпоху Возрождения полиматия являлась частью идеи о совершенном человеке, который должен был быть одновременно ученым и художником, и при этом быть развитым физически', ' Леонардо да Винчи гордился своей способностью гнуть железные прутья примерно в той же степени, что Моной Лизой. Я был здоров, молод, весел, деньги у меня не переводились, заботы еще не успели завестись - я жил без оглядки, делал что хотел, процветал, одним словом. Мне тогда и в голову не приходило, что человек не растение и процветать ему долго нельзя. Молодость ест пряники золоченые, да и думает, что это-то и есть хлеб насущный; а придет время - и хлебца напросишься. Но толковать об этом не для чего.']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1wrEGqBSWhAr"},"source":["### sub\n","ищет шаблон в строке и заменяет все совпадения на указанную подстроку\n","\n","параметры: (pattern, repl, string)"]},{"cell_type":"code","metadata":{"id":"az3KxKWwWhAr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605020046140,"user_tz":-180,"elapsed":980,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"7145c2aa-53f6-446b-9d27-d5c0ef7b7c6d"},"source":["result = re.sub('a', 'b', 'abcabc')\n","print (result)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["bbcbbc\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qD0n7_HPWhAt"},"source":["**Задание**: напишите регулярное выражение, которое позволит заменить все цифры в строке на \"DIG\"."]},{"cell_type":"code","metadata":{"id":"s_Sdu7xlWhAu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605020217203,"user_tz":-180,"elapsed":866,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"1af8faf3-c3d0-4506-fab2-3a4c3a6e3c80"},"source":["result = re.sub('\\d', 'DIG', 'v58ytv38bv38eg2f3g9')\n","print (result)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["vDIGDIGytvDIGDIGbvDIGDIGegDIGfDIGgDIG\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"b8__oi1PWhAv"},"source":["**Задание**: напишите  регулярное выражение, которое позволит убрать url из строки."]},{"cell_type":"code","metadata":{"id":"KwNS9zt4WhAv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605020314085,"user_tz":-180,"elapsed":778,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"c4df1b8c-10b8-4208-e47a-6a2d88f802b4"},"source":["result = re.sub('url:', '', 'url:wikipedia.org')\n","print (result)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["wikipedia.org\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gStgBJy2WhAx"},"source":["### compile\n","компилирует регулярное выражение в отдельный объект"]},{"cell_type":"code","metadata":{"id":"JstTupisWhAy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605020338577,"user_tz":-180,"elapsed":709,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"ba6834f2-7a90-4a41-ac76-4aa7e1ef5645"},"source":["# Пример: построение списка всех слов строки:\n","prog = re.compile('[А-Яа-яё\\-]+')\n","prog.findall(\"Слова? Да, больше, ещё больше слов! Что-то ещё.\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Слова', 'Да', 'больше', 'ещё', 'больше', 'слов', 'Что-то', 'ещё']"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"WXEXc3G0WhA2"},"source":["**Задание**: для выбранной строки постройте список слов, которые длиннее трех символов."]},{"cell_type":"code","metadata":{"id":"nFvnIWbUWhA2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605020686563,"user_tz":-180,"elapsed":601,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"5f7f17ac-f0b0-4235-f30d-30c0299d1b11"},"source":["prog = re.compile('\\w{4}\\w*')\n","prog.findall(\"Слова? Да, больше, ещё больше слов! Что-то ещё.\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Слова', 'больше', 'больше', 'слов']"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"markdown","metadata":{"id":"SQDNZ3HQWhA3"},"source":["**Задание**: вернуть список доменов (@gmail.com) из списка адресов электронной почты:\n","\n","```\n","abc.test@gmail.com, xyz@test.in, test.first@analyticsvidhya.com, first.test@rest.biz\n","```"]},{"cell_type":"code","metadata":{"id":"haZ5qn3DWhA3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605056323321,"user_tz":-180,"elapsed":1385,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"e5d133b9-aec2-4385-c422-09df5c6454db"},"source":["prog = re.compile('@\\w*\\.\\w*')\n","prog.findall(\"abc.test@gmail.com, xyz@test.in, test.first@analyticsvidhya.com, first.test@rest.biz\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['@gmail.com', '@test.in', '@analyticsvidhya.com', '@rest.biz']"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"BPgOkJXhZxJ-"},"source":["## Бонус 2: Word2Vec\n","\n","Векторные модели, которые мы рассматривали до этого (BOW, мешок слов; TF-IDF), условно называются *счётными*. Они основываются на том, что так или иначе \"считают\" слова и их соседей, и на основе этого строят вектора для слов. "]},{"cell_type":"markdown","metadata":{"id":"CL7VqGHwZmUG"},"source":["\n","Другой класс моделей, который повсеместно распространён на сегодняшний день, называется *предсказательными* моделями. Идея этих моделей заключается в использовании нейросетевых архитектур, которые \"предсказывают\" (а не считают) соседей для каждого слова.\n","\n","Одной из самых известных таких моделей является `word2vec`. Технология основана на нейронной сети, предсказывающей вероятность встретить слово в заданном контексте. Этот инструмент был разработан группой исследователей Google в 2013 году, руководителем проекта был Томаш Миколов (сейчас работает в Facebook). Вот две самые главные статьи:\n","\n","* [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/pdf/1301.3781.pdf)\n","* [Distributed Representations of Words and Phrases and their Compositionality](https://arxiv.org/abs/1310.4546)\n","\n","\n","Полученные таким образом вектора называются *распределенными представлениями слов*, вложениями или **эмбеддингами**."]},{"cell_type":"markdown","metadata":{"id":"6V7k_qL1Z-UG"},"source":["### Как это обучается?\n","Мы задаём вектор для каждого слова с помощью матрицы $w$ и вектор контекста с помощью матрицы $W$. По сути, word2vec является обобщающим названием для двух архитектур Skip-Gram и Continuous Bag-Of-Words (CBOW).  \n","\n","![](https://www.researchgate.net/profile/Daniel_Braun6/publication/326588219/figure/fig1/AS:652185784295425@1532504616288/Continuous-Bag-of-words-CBOW-CB-and-Skip-gram-SG-training-model-illustrations.png)\n","\n","**CBOW** предсказывает текущее слово, исходя из окружающего его контекста. \n","\n","**Skip-gram**, наоборот, использует текущее слово, чтобы предугадывать окружающие его слова. \n","\n","### Как это работает?\n","Word2vec принимает большой текстовый корпус в качестве входных данных и сопоставляет каждому слову вектор, выдавая координаты слов на выходе. Сначала он создает словарь, «обучаясь» на входных текстовых данных, а затем вычисляет векторное представление слов. \n","\n","Векторное представление основывается на *контекстной близости*: слова, встречающиеся в тексте рядом с одинаковыми словами (а следовательно, согласно дистрибутивной гипотезе, имеющие схожий смысл), в векторном представлении будут иметь близкие координаты векторов-слов. Для вычисления близости слов используется косинусное расстояние между их векторами.\n","\n","\n","С помощью дистрибутивных векторных моделей можно строить семантические пропорции (они же аналогии: А относится к B так же, как C относится к D) и решать примеры:\n","\n","* *король: мужчина = королева: женщина* \n"," $\\Rightarrow$ \n","* *король - мужчина + женщина = королева*"]},{"cell_type":"markdown","metadata":{"id":"l0MPc-3NaOoE"},"source":["![w2v](https://cdn-images-1.medium.com/max/2600/1*sXNXYfAqfLUeiDXPCo130w.png)"]},{"cell_type":"markdown","metadata":{"id":"29tswg7NalHk"},"source":["Для слов нет лейблов, но мы используем слова в контексте для сбора обучающей выборки.\n","\n","## Skip gram\n","\n","(Предсказание контекста по слову, один из основных параметров - windows_size)\n","\n","![Замещающий текст](http://mccormickml.com/assets/word2vec/training_data.png)\n","\n","1. Представляем корпус текста в формате One-hot encoding, подаем вектор на вход нейросети\n","\n","2. В качестве активации последнего слоя используем softmax -> переходим в пространство вероятностей (как будто задача классификации с очень большим количеством классов)\n","\n","3. Предсказываем слово контекста по максимальной вероятности\n","\n","![Замещающий текст](https://miro.medium.com/max/875/0*FD_ZSVKFywSg-CJM.png)\n","\n","Модель хорошо работает с небольшим количеством тренировочных данных\n","\n"]},{"cell_type":"markdown","metadata":{"id":"tTVRguH2Ryef"},"source":["## CBOW\n","\n","![](https://iksinc.files.wordpress.com/2015/04/screen-shot-2015-04-12-at-10-58-21-pm.png)\n","\n","Тренируется быстрее, чем SkipGram, лучше точность на редких словах\n"]},{"cell_type":"markdown","metadata":{"id":"r7KSbkvwa76d"},"source":["### Проблемы\n","Невозможно установить тип семантических отношений между словами: синонимы, антонимы и т.д. будут одинаково близки, потому что обычно употребляются в схожих контекстах. Поэтому близкие в векторном пространстве слова называют *семантическими ассоциатами*. Это значит, что они семантически связаны, но как именно — непонятно.\n","\n","\n","## RusVectōrēs\n","\n","\n","На сайте [RusVectōrēs](https://rusvectores.org/ru/) собраны предобученные на различных данных модели для русского языка, а также можно поискать наиболее близкие слова к заданному, посчитать семантическую близость нескольких слов и порешать примеры с помощью «калькулятора семантической близости».\n","\n","\n","Для других языков также можно найти предобученные модели — например, модели [fastText](https://fasttext.cc/docs/en/english-vectors.html) и [GloVe](https://nlp.stanford.edu/projects/glove/)."]},{"cell_type":"markdown","metadata":{"id":"SwcFQkV7bA0M"},"source":["## Gensim\n","\n","Использовать предобученную модель эмбеддингов или обучить свою можно с помощью библиотеки `gensim`. Вот [ее документация](https://radimrehurek.com/gensim/models/word2vec.html).\n","\n","### Как использовать готовую модель\n","\n","Модели word2vec бывают разных форматов:\n","\n","* .vec.gz — обычный файл (текстовый)\n","* .bin.gz — бинарный файл\n","\n","Загружаются они с помощью одного и того же класса `KeyedVectors`, меняется только параметр `binary` у функции `load_word2vec_format`. \n","\n","Если же эмбеддинги обучены **не** с помощью word2vec, то для загрузки нужно использовать функцию `load`. Т.е. **для загрузки предобученных эмбеддингов *glove, fasttext, bpe* и любых других нужна именно она**.\n","\n","Скачаем с RusVectōrēs модель для русского языка, обученную на НКРЯ образца 2015 г. "]},{"cell_type":"code","metadata":{"id":"kTnxWXhubJ3W"},"source":["import urllib.request # библиотека для скачивания данных\n","import gensim # библиотека для загрузки и использвоания моделй w2v\n","from gensim.models import word2vec # непосредственно методы w2v"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yhY2nOyTbM1h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605457824725,"user_tz":-180,"elapsed":37448,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"47742f14-85e9-482d-ae83-3567da5d56a5"},"source":["# скачиваем модель ruscorpora_mystem_cbow_300 с сайта rusvectores\n","# 300 - размерность вектора embeddings для слов\n","\n","urllib.request.urlretrieve(\"http://rusvectores.org/static/models/rusvectores2/ruscorpora_mystem_cbow_300_2_2015.bin.gz\", \"ruscorpora_mystem_cbow_300_2_2015.bin.gz\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('ruscorpora_mystem_cbow_300_2_2015.bin.gz',\n"," <http.client.HTTPMessage at 0x7ff74c48ac18>)"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"markdown","metadata":{"id":"iIY8HdoEbRCE"},"source":["Загружаем скачанную модель. Обратите внимание, что мы скачали бинарный файл (.bin.gz), поэтому у функции load_word2vec_format() параметр binary=True"]},{"cell_type":"code","metadata":{"id":"w0YvC5bBbVVm"},"source":["model_path = 'ruscorpora_mystem_cbow_300_2_2015.bin.gz'\n","\n","model_ru = gensim.models.KeyedVectors.load_word2vec_format(model_path, binary=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"udp_Onx4bX3D"},"source":["Посмотрим на ближайших соседей следующей группы слов:"]},{"cell_type":"code","metadata":{"id":"y7WoLtzabZ57"},"source":["words = ['день_S', 'ночь_S', 'человек_S', 'семантика_S', 'биткоин_S']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W1wix4nwbfLf"},"source":["Частеречные тэги (например, _S, тег части речи слова) нужны, поскольку это специфика скачанной модели - она была натренирована на словах, размеченных по частям речи (и лемматизированных). \n","\n","**NB!** В названиях моделей на `rusvectores` указано, какой тегсет (набор обозначений тегов) они используют (mystem, upos и т.д.)\n","\n","Попросим у модели 10 ближайших соседей для каждого слова и косинусные близости для каждого:"]},{"cell_type":"code","metadata":{"id":"_xIsRf1Ebhrd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605056525464,"user_tz":-180,"elapsed":943,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"4f0b690e-2e96-4522-c92d-bbf7c4be70e3"},"source":["for word in words:\n","    # есть ли слово в модели? \n","    if word in model_ru:\n","        print(word)\n","        # смотрим на вектор слова (его размерность 300, смотрим на первые 10 чисел)\n","        print(model_ru[word][:10])\n","        # выдаем 10 ближайших соседей слова:\n","        for word, sim in model_ru.most_similar(positive=[word], topn=10):\n","            # слово + коэффициент косинусной близости\n","            print(word, ': ', sim)\n","        print('\\n')\n","    else:\n","        # Увы!\n","        print('Увы, слова \"%s\" нет в модели!' % word)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["день_S\n","[-0.02580778  0.00970898  0.01941961 -0.02332282  0.02017624  0.07275085\n"," -0.01444375  0.03316632  0.01242602  0.02833412]\n","неделя_S :  0.7165195941925049\n","месяц_S :  0.631048858165741\n","вечер_S :  0.5828739404678345\n","утро_S :  0.5676207542419434\n","час_S :  0.5605547428131104\n","минута_S :  0.5297019481658936\n","гекатомбеон_S :  0.4897990822792053\n","денек_S :  0.48224714398384094\n","полчаса_S :  0.48217129707336426\n","ночь_S :  0.478074848651886\n","\n","\n","ночь_S\n","[-0.00688948  0.00408364  0.06975466 -0.00959525  0.0194835   0.04057068\n"," -0.00994112  0.06064967 -0.00522624  0.00520327]\n","вечер_S :  0.6946247816085815\n","утро_S :  0.57301926612854\n","ноченька_S :  0.5582467317581177\n","рассвет_S :  0.5553582906723022\n","ночка_S :  0.5351512432098389\n","полдень_S :  0.5334426164627075\n","полночь_S :  0.478694349527359\n","день_S :  0.4780748784542084\n","сумерки_S :  0.4390218257904053\n","фундерфун_S :  0.4340824782848358\n","\n","\n","человек_S\n","[ 0.02013756 -0.02670703 -0.02039861 -0.05477146  0.00086402 -0.01636335\n","  0.04240306 -0.00025525 -0.14045681  0.04785006]\n","женщина_S :  0.5979775190353394\n","парень_S :  0.4991787374019623\n","мужчина_S :  0.4767409563064575\n","мужик_S :  0.47384002804756165\n","россиянин_S :  0.47190436720848083\n","народ_S :  0.4654741883277893\n","согражданин_S :  0.45378512144088745\n","горожанин_S :  0.44368088245391846\n","девушка_S :  0.44314485788345337\n","иностранец_S :  0.43849867582321167\n","\n","\n","семантика_S\n","[-0.03066749  0.0053851   0.1110732   0.0152335   0.00440643  0.00384104\n","  0.00096944 -0.03538784 -0.00079585  0.03220548]\n","семантический_A :  0.5334584712982178\n","понятие_S :  0.5030269622802734\n","сочетаемость_S :  0.4817051291465759\n","актант_S :  0.47596412897109985\n","хронотоп_S :  0.46330299973487854\n","метафора_S :  0.46158894896507263\n","мышление_S :  0.4610119163990021\n","парадигма_S :  0.45796656608581543\n","лексема_S :  0.45688074827194214\n","смысловой_A :  0.4543077349662781\n","\n","\n","Увы, слова \"биткоин_S\" нет в модели!\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n","  if np.issubdtype(vec.dtype, np.int):\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"oSKvti4ObmKP"},"source":["Найдем похожесть пары слов функцией ```similarity()``` (там используется косинусная мера схожести):"]},{"cell_type":"code","metadata":{"id":"0dbBhOf3bvZj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605457865916,"user_tz":-180,"elapsed":922,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"dc070a3d-2db4-4030-836d-4e05b8782ecc"},"source":["print(model_ru.similarity('человек_S', 'обезьяна_S'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.23895611\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n","  if np.issubdtype(vec.dtype, np.int):\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"Y2vjNfsXb1bF"},"source":["У загруженной модели много различных функций. Например, можно решать задачи на семантическую близость.\n","\n","Что получится, если вычесть из пиццы Италию и прибавить Сибирь?\n","\n","Для решения примера в качестве параметров метода ```most_similar()``` необходимо передать:\n","* positive — вектора, которые мы складываем\n","* negative — вектора, которые вычитаем\n","\n","*Замечание:* не забываем взять самый близкий элемент, для этого необходимо указать ```[0][0]```."]},{"cell_type":"markdown","metadata":{"id":"0HE75DAGb40E"},"source":["Что получится, если вычесть из пиццы Италию и прибавить Сибирь?"]},{"cell_type":"code","metadata":{"id":"Nz81U7aKb8KD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605457871637,"user_tz":-180,"elapsed":1260,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"fbdeb608-1e77-4998-c03d-8c10dbd52e22"},"source":["print(model_ru.most_similar(negative=[ 'италия_S'], positive=['пицца_S','сибирь_S'])[0][0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["пельмень_S\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n","  if np.issubdtype(vec.dtype, np.int):\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"yWRxadscb-oY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605457879279,"user_tz":-180,"elapsed":995,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"26dee7a3-e8d0-4897-f546-720c8b9b383f"},"source":["print(model_ru.most_similar(positive=['футбол_S', 'хоккей_S'], negative=['россия_S'])[0][0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["волейбол_S\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n","  if np.issubdtype(vec.dtype, np.int):\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"mfmyC1sQcAme"},"source":["**Задание.** Придумайте и проверьте с помощью метода `most_similar` несколько аналогий"]},{"cell_type":"code","metadata":{"id":"UQc4X0h405qA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605457893416,"user_tz":-180,"elapsed":1106,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"17aff099-8e1b-4d88-d036-c78f3d9b520f"},"source":["print(model_ru.most_similar(negative=[ 'сша_S'], positive=['бургер_S','китай_S'])[0][0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["бурдюк_S\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n","  if np.issubdtype(vec.dtype, np.int):\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"FnsZ0T0S1eQf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605457898277,"user_tz":-180,"elapsed":879,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"a16a306d-046b-44b6-8018-57bc739c61ac"},"source":["print(model_ru.most_similar(positive=['программирование_S', 'психология_S'], negative=['студент_S'])[0][0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["методология_S\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n","  if np.issubdtype(vec.dtype, np.int):\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"5dnmf1J61pEC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605457901140,"user_tz":-180,"elapsed":966,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"c757d3d3-c260-4880-f045-43156b9eadcb"},"source":["print(model_ru.most_similar(positive=['евразия_S', 'мир_S'], negative=['россия_S', 'казахстан_S'])[0][0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["космичный_A\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n","  if np.issubdtype(vec.dtype, np.int):\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"apY4f9DHcIn7"},"source":["Метод ```doesnt_match()``` находит \"лишнее слово\" в группе слов:"]},{"cell_type":"code","metadata":{"id":"LoHVj3XscPTf","colab":{"base_uri":"https://localhost:8080/","height":123},"executionInfo":{"status":"ok","timestamp":1604733444691,"user_tz":-180,"elapsed":765,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"32659c77-6ac8-455a-984a-b8c508b67191"},"source":["model_ru.doesnt_match('пицца_S пельмень_S хот-дог_S ананас_S'.split())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n","  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n","/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n","  if np.issubdtype(vec.dtype, np.int):\n"],"name":"stderr"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'ананас_S'"]},"metadata":{"tags":[]},"execution_count":156}]},{"cell_type":"markdown","metadata":{"id":"Rz5cyw-ScRFd"},"source":["**Задание.** Придумайте и проверьте с помощью метода `doesnt_match` несколько последовательностей с лишними словами"]},{"cell_type":"code","metadata":{"id":"b91U0KZ206pE","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1605457957525,"user_tz":-180,"elapsed":833,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"5c6c8051-9526-4d61-98c1-8af559a0fb12"},"source":["model_ru.doesnt_match('итмо_S тусур_S спбгу_S мгимо_S'.split())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n","  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n","/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n","  if np.issubdtype(vec.dtype, np.int):\n"],"name":"stderr"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'мгимо_S'"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"gtLCe_2p1Gkt","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1605457965818,"user_tz":-180,"elapsed":3293,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"3b8394b0-87be-440c-9291-83519d691ec1"},"source":["model_ru.doesnt_match('панк_S рок_S поп_S рэп_S'.split())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n","  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n","/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n","  if np.issubdtype(vec.dtype, np.int):\n"],"name":"stderr"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'поп_S'"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"chDAm6ag12FR","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1605457970322,"user_tz":-180,"elapsed":890,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"3aeadf31-2406-468c-f077-12c97206de27"},"source":["model_ru.doesnt_match('режиссер_S актер_S сценарист_S продюссер_S'.split())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n","  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n","/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n","  if np.issubdtype(vec.dtype, np.int):\n"],"name":"stderr"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'продюссер_S'"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"markdown","metadata":{"id":"16c7mAZ_kd68"},"source":["### Как обучить свою модель\n","\n","В качестве обучающих данных возьмем размеченные и неразмеченные отзывы о фильмах (датасет взят с Kaggle)."]},{"cell_type":"code","metadata":{"id":"EX66ryM0klX5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605056855476,"user_tz":-180,"elapsed":4490,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"8fb90941-da1d-4659-8f85-3ec3b25a347a"},"source":["# скачиваем датасет\n","! wget https://raw.githubusercontent.com/ancatmara/data-science-nlp/master/data/w2v/train/unlabeledTrainData.tsv"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2020-11-11 01:07:31--  https://raw.githubusercontent.com/ancatmara/data-science-nlp/master/data/w2v/train/unlabeledTrainData.tsv\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 67281491 (64M) [text/plain]\n","Saving to: ‘unlabeledTrainData.tsv’\n","\n","unlabeledTrainData. 100%[===================>]  64.16M   176MB/s    in 0.4s    \n","\n","2020-11-11 01:07:34 (176 MB/s) - ‘unlabeledTrainData.tsv’ saved [67281491/67281491]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-gLAXFcvkiOM"},"source":["Загрузим датасет в датафрейм и посмотрим на него, делаем это с помощью уже привычной библиотеки **pandas**:"]},{"cell_type":"code","metadata":{"id":"okHBivCVksUW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605056881948,"user_tz":-180,"elapsed":1134,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"a1742552-0d2b-4fbf-d572-471834592586"},"source":["# считываем данные в формате csv\n","import pandas as pd\n","data = pd.read_csv(\"unlabeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3)\n","\n","len(data)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["50000"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"qHdjpqcCkyT1","colab":{"base_uri":"https://localhost:8080/","height":197},"executionInfo":{"status":"ok","timestamp":1605056886240,"user_tz":-180,"elapsed":855,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"8959ae8d-c86a-4a20-ec38-a60333c4fa1f"},"source":["data.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>review</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>\"9999_0\"</td>\n","      <td>\"Watching Time Chasers, it obvious that it was...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>\"45057_0\"</td>\n","      <td>\"I saw this film about 20 years ago and rememb...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>\"15561_0\"</td>\n","      <td>\"Minor Spoilers&lt;br /&gt;&lt;br /&gt;In New York, Joan B...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>\"7161_0\"</td>\n","      <td>\"I went to see this film with a great deal of ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>\"43971_0\"</td>\n","      <td>\"Yes, I agree with everyone on this site this ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          id                                             review\n","0   \"9999_0\"  \"Watching Time Chasers, it obvious that it was...\n","1  \"45057_0\"  \"I saw this film about 20 years ago and rememb...\n","2  \"15561_0\"  \"Minor Spoilers<br /><br />In New York, Joan B...\n","3   \"7161_0\"  \"I went to see this film with a great deal of ...\n","4  \"43971_0\"  \"Yes, I agree with everyone on this site this ..."]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"im53Mp3yk1ld","colab":{"base_uri":"https://localhost:8080/","height":118},"executionInfo":{"status":"ok","timestamp":1605056890210,"user_tz":-180,"elapsed":906,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"20eb73e6-1f4e-4663-c385-24b07587ea85"},"source":["data.iloc[10]['review']"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\"After reading the comments for this movie, I am not sure whether I should be angry, sad or sickened. Seeing comments typical of people who a)know absolutely nothing about the military or b)who base everything they think they know on movies like this or on CNN reports about Abu-Gharib makes me wonder about the state of intellectual stimulation in the world.<br /><br />At the time I type this the number of people in the US military: 1.4 million on Active Duty with another almost 900,000 in the Guard and Reserves for a total of roughly 2.3 million.<br /><br />The number of people indicted for abuses at at Abu-Gharib: Currently less than 20<br /><br />That makes the total of people indicted .00083% of the total military. Even if you indict every single military member that ever stepped in to Abu-Gharib, you would not come close to making that a whole number. <br /><br />The flaws in this movie would take YEARS to cover. I understand that it\\'s supposed to be sarcastic, but in reality, the writer and director are trying to make commentary about the state of the military without an enemy to fight. In reality, the US military has been at its busiest when there are not conflicts going on. The military is the first called for disaster relief and humanitarian aid missions. When the tsunami hit Indonesia, devestating the region, the US military was the first on the scene. When the chaos of the situation overwhelmed the local governments, it was military leadership who looked at their people, the same people this movie mocks, and said make it happen. Within hours, food aid was reaching isolated villages. Within days, airfields were built, cargo aircraft started landing and a food distribution system was up and running. Hours and days, not weeks and months. Yes there are unscrupulous people in the US military. But then, there are in every walk of life, every occupation. But to see people on this website decide that 2.3 million men and women are all criminal, with nothing on their minds but thoughts of destruction or mayhem is an absolute disservice to the things that they do every day. One person on this website even went so far as to say that military members are in it for personal gain. Wow! Entry level personnel make just under $8.00 an hour assuming a 40 hour work week. Of course, many work much more than 40 hours a week and those in harm\\'s way typically put in 16-18 hour days for months on end. That makes the pay well under minimum wage. So much for personal gain. I beg you, please make yourself familiar with the world around you. Go to a nearby base, get a visitor pass and meet some of the men and women you are so quick to disparage. You would be surprised. The military no longer accepts people in lieu of prison time. They require a minimum of a GED and prefer a high school diploma. The middle ranks are expected to get a minimum of undergraduate degrees and the upper ranks are encouraged to get advanced degrees.\"'"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"markdown","metadata":{"id":"knptEXQtkhW7"},"source":["Нам необходимо отчистить данные от лишнего: убрать ссылки, html-разметку и небуквенные символы. Затем нужно привести все к нижнему регистру и токенизировать. \n","\n","На выходе мы хотим получить массив из предложений, каждое из которых представляет собой массив слов.\n","\n","Импортируем необходимые библиотеки и методы (некоторые уже были испортированы ранее, но для полноты картины оставим их):"]},{"cell_type":"code","metadata":{"id":"G0mEEpUmk6J6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605056916800,"user_tz":-180,"elapsed":2604,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"21656cde-96ee-466b-c640-86f6613312ad"},"source":["import nltk.data # библиотека Natural Language Toolkit\n","import re   # библиотека для регулярных выражений\n","from bs4 import BeautifulSoup # библиотека для парсинга xml\n","from nltk.corpus import stopwords # стоп-слова из NLTK\n","from nltk.tokenize import sent_tokenize, RegexpTokenizer  # токенизаторы из NLTK\n","nltk.download('punkt') # пунктуация для правильной работы токенизатора"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"Nhz3Olb4lDvz"},"source":["tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0yhts6MulJaD"},"source":["Функции для очистки данных:\n"]},{"cell_type":"code","metadata":{"id":"_veEBUBZlKN6"},"source":["def review_to_wordlist(review, remove_stopwords=False):\n","    # убираем ссылки вне тегов\n","    review = re.sub(r\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\", \" \", review)\n","    # достаем сам текст\n","    review_text = BeautifulSoup(review, \"lxml\").get_text()\n","    # оставляем только буквенные символы\n","    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n","    # приводим к нижнему регистру и разбиваем на слова по символу пробела\n","    words = review_text.lower().split()\n","    if remove_stopwords:\n","      # убираем стоп-слова\n","        stops = stopwords.words(\"english\")\n","        words = [w for w in words if not w in stops]\n","    return(words)\n","\n","def review_to_sentences(review, tokenizer, remove_stopwords=False):\n","    raw_sentences = tokenizer.tokenize(review.strip())\n","    sentences = []\n","    for raw_sentence in raw_sentences:\n","        if len(raw_sentence) > 0:\n","            sentences.append(review_to_wordlist(raw_sentence, remove_stopwords))\n","    return sentences"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qfEIEFIJlTBH"},"source":["Проходим по всему датасету и парсим написанной выше функцией  текст в списки слов, удаляя при этом лишнее:"]},{"cell_type":"code","metadata":{"id":"Ujigc0V2lWmw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605057079629,"user_tz":-180,"elapsed":145377,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"60f0a53e-d408-49e5-8d26-13e056236eec"},"source":["sentences = []  \n","\n","print(\"Parsing sentences from training set...\")\n","for review in data[\"review\"]:\n","    sentences += review_to_sentences(review, tokenizer)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Parsing sentences from training set...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:273: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n","  ' Beautiful Soup.' % markup)\n","/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:273: UserWarning: \"b'..'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n","  ' Beautiful Soup.' % markup)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"fYePh1_GlVH5"},"source":["Посмотрим, что получилось:"]},{"cell_type":"code","metadata":{"id":"RYsO6Ya7lanY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605057179037,"user_tz":-180,"elapsed":856,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"4f220e2e-71d6-4500-ea07-8b6de46220af"},"source":["print(len(sentences))\n","print(sentences[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["528987\n","['watching', 'time', 'chasers', 'it', 'obvious', 'that', 'it', 'was', 'made', 'by', 'a', 'bunch', 'of', 'friends']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xNp27TyyljLr"},"source":["# это понадобится нам позже для обучения другой модели эмбеддингов \n","\n","with open('clean_text.txt', 'w') as f:\n","    for s in sentences[:5000]:\n","        f.write(' '.join(s))\n","        f.write('\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fWVpmrVMlm0u"},"source":["Обучаем и сохраняем модель. \n","\n","\n","Основные параметры:\n","* данные должны быть итерируемым объектом \n","* size — размер вектора, \n","* window — размер окна наблюдения,\n","* min_count — мин. частотность слова в корпусе,\n","* sg — используемый алгоритм обучения (0 — CBOW, 1 — Skip-gram),\n","* sample — порог для downsampling'a высокочастотных слов,\n","* workers — количество потоков,\n","* alpha — learning rate,\n","* iter — количество итераций,\n","* max_vocab_size — позволяет выставить ограничение по памяти при создании словаря (т.е. если ограничение превышается, то низкочастотные слова будут выбрасываться). Для сравнения: 10 млн слов = 1Гб RAM.\n","\n","**NB!** Обратите внимание, что тренировка модели не включает препроцессинг! Это значит, что избавляться от пунктуации, приводить слова к нижнему регистру, лемматизировать их, проставлять частеречные теги придется до тренировки модели (если, конечно, это необходимо для вашей задачи). Т.е. в каком виде слова будут в исходном тексте, в таком они будут и в модели."]},{"cell_type":"code","metadata":{"id":"TEECgAnQlppC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605057520052,"user_tz":-180,"elapsed":126574,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"590d138a-2a12-4d60-db06-1ab91c167b74"},"source":["print(\"Training model...\")\n","# обучаем модель с векторами размерности 300, длиной окна 10\n","%time model_en = word2vec.Word2Vec(sentences, workers=4, size=300, min_count=10, window=10, sample=1e-3)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training model...\n","CPU times: user 3min 53s, sys: 1.08 s, total: 3min 54s\n","Wall time: 2min 5s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7kIOEvpIlt3K"},"source":["Смотрим, сколько в модели слов."]},{"cell_type":"code","metadata":{"id":"nM8Cpervlv4_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605057537613,"user_tz":-180,"elapsed":786,"user":{"displayName":"Валерия Артамонова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHHdmGMp4FeGxtclHCM2QPSNfF0btY_bQL5-IhiA=s64","userId":"11457505406040387608"}},"outputId":"04edf547-2721-413b-c6cd-58221e60d2ec"},"source":["print(len(model_en.wv.vocab))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["28308\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jvSW75bbl5OB"},"source":["Попробуем оценить модель вручную, порешав примеры. Несколько дано ниже, попробуйте придумать свои."]},{"cell_type":"code","metadata":{"id":"wpOa55MXl0br","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604734048903,"user_tz":-180,"elapsed":981,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"dfb04460-d947-4324-e0b5-7ef8222d29da"},"source":["print(model_en.wv.most_similar(positive=[\"woman\", \"actor\"], negative=[\"man\"], topn=1))\n","print(model_en.wv.most_similar(positive=[\"dogs\", \"man\"], negative=[\"dog\"], topn=1))\n","\n","print(model_en.wv.most_similar(\"usa\", topn=3))\n","\n","print(model_en.wv.doesnt_match(\"comedy thriller western novel\".split()))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[('actress', 0.7793270945549011)]\n","[('men', 0.6503796577453613)]\n","[('europe', 0.7524359226226807), ('germany', 0.7389851808547974), ('north', 0.7247494459152222)]\n","novel\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n","  if np.issubdtype(vec.dtype, np.int):\n","/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n","  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"CJoBb8olmGYQ"},"source":["### Как дообучить существующую модель\n","\n","При тренировке модели \"с нуля\" веса инициализируются случайно, однако, можно использовать для инициализации векторов веса из предобученной модели, таким образом как бы дообучая ее.\n","\n","Сначала посмотрим близость какой-нибудь пары слов в имеющейся модели, чтобы потом сравнить результат с дообученной."]},{"cell_type":"code","metadata":{"id":"171hCwa6mJiz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604734099024,"user_tz":-180,"elapsed":760,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"37f7d73a-daea-4b0b-a537-5c53916096d5"},"source":["model_en.wv.similarity('lion', 'rabbit')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n","  if np.issubdtype(vec.dtype, np.int):\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["0.287468"]},"metadata":{"tags":[]},"execution_count":173}]},{"cell_type":"markdown","metadata":{"id":"sYpQqzcamNL1"},"source":["В качестве дополнительных данных для обучения возьмем английский текст «Алисы в Зазеркалье»."]},{"cell_type":"code","metadata":{"id":"YMEwE7OimPe9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604734049238,"user_tz":-180,"elapsed":1307,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"944308c5-73bc-4576-e860-998304c715cb"},"source":["! wget https://raw.githubusercontent.com/ancatmara/data-science-nlp/master/data/w2v/train/alice.txt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2020-11-07 07:27:28--  https://raw.githubusercontent.com/ancatmara/data-science-nlp/master/data/w2v/train/alice.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 167631 (164K) [text/plain]\n","Saving to: ‘alice.txt’\n","\n","alice.txt           100%[===================>] 163.70K  --.-KB/s    in 0.04s   \n","\n","2020-11-07 07:27:28 (3.80 MB/s) - ‘alice.txt’ saved [167631/167631]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sV2bGBFTmT0z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604734123072,"user_tz":-180,"elapsed":866,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"14701b4d-58b9-4b64-b9e4-41e0bc94f6c1"},"source":["with open(\"alice.txt\", 'r', encoding='utf-8') as f:\n","    text = f.read()\n","\n","# убираем переносы строк, токенизируем текст\n","\n","text = re.sub('\\n', ' ', text)\n","sents = sent_tokenize(text)\n","\n","punct = '!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~„“«»†*—/\\-‘’'\n","clean_sents = []\n","\n","# убираем всю пунктуацию и делим текст на слова по пробелу\n","for sent in sents:\n","    s = [w.lower().strip(punct) for w in sent.split()]\n","    clean_sents.append(s)\n","    \n","print(clean_sents[:2])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[['through', 'the', 'looking-glass', 'by', 'lewis', 'carroll', 'chapter', 'i', 'looking-glass', 'house', 'one', 'thing', 'was', 'certain', 'that', 'the', 'white', 'kitten', 'had', 'had', 'nothing', 'to', 'do', 'with', 'it', '', 'it', 'was', 'the', 'black', 'kitten’s', 'fault', 'entirely'], ['for', 'the', 'white', 'kitten', 'had', 'been', 'having', 'its', 'face', 'washed', 'by', 'the', 'old', 'cat', 'for', 'the', 'last', 'quarter', 'of', 'an', 'hour', 'and', 'bearing', 'it', 'pretty', 'well', 'considering', 'so', 'you', 'see', 'that', 'it', 'couldn’t', 'have', 'had', 'any', 'hand', 'in', 'the', 'mischief']]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"T2O6QnwcmZYo"},"source":["Чтобы дообучить модель, надо сначала ее сохранить, а потом загрузить. Все параметры тренировки (размер вектора, мин. частота слова и т.п.) будут взяты из загруженной модели, т.е. задать их заново нельзя.\n","\n","**NB!** Дообучить можно только полную модель (сохраненные при обучении веса и параметры модели, то есть обект самой модели), а `KeyedVectors` (просто пары \"слово - вектор\") — нельзя. Поэтому сохранять модель нужно в соотвествующем формате. Подробнее о разнице [вот тут](https://radimrehurek.com/gensim/models/keyedvectors.html)."]},{"cell_type":"code","metadata":{"id":"-z28eER7mc-Y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604734127898,"user_tz":-180,"elapsed":1449,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"77b6e2c1-d7b8-40e8-aa37-5b121cf338e5"},"source":["model_path = \"movie_reviews.model\"\n","\n","# так можно сохранить модель для последующего дообучения\n","print(\"Saving model...\")\n","model_en.save(model_path)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Saving model...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"a-i0jCyGme7C","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604734131688,"user_tz":-180,"elapsed":1794,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"67fed096-e891-49da-84c7-dfe250b5326b"},"source":["# загружаем нашу обученную модель и дообучаем на текстах \"Алисы\"\n","\n","model = word2vec.Word2Vec.load(model_path)\n","\n","model.build_vocab(clean_sents, update=True)\n","model.train(clean_sents, total_examples=model.corpus_count, epochs=5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(96730, 150225)"]},"metadata":{"tags":[]},"execution_count":178}]},{"cell_type":"code","metadata":{"id":"_pY1ftSImhv1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604734134910,"user_tz":-180,"elapsed":780,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"82c75f15-66a2-4b91-c1fe-2acb9d98f9f2"},"source":["model.wv.similarity('lion', 'rabbit')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n","  if np.issubdtype(vec.dtype, np.int):\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["0.30270875"]},"metadata":{"tags":[]},"execution_count":179}]},{"cell_type":"markdown","metadata":{"id":"b02DdZigmkWw"},"source":["Лев и кролик стали ближе друг к другу!"]},{"cell_type":"markdown","metadata":{"id":"eLOxX4yUmsPU"},"source":["Можно нормализовать вектора, тогда модель будет занимать меньше RAM. Однако после этого её нельзя дотренировывать. Здесь используется L2-нормализация: вектора нормализуются так, что если сложить квадраты всех элементов вектора, в сумме получится 1. \n","\n","Кроме того, сохраним не полные вектора, а `KeyedVectors`."]},{"cell_type":"code","metadata":{"id":"eyObwn1GmuuS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604734140048,"user_tz":-180,"elapsed":1062,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"6133794f-da15-44db-e318-311c4ff5a6a6"},"source":["model.init_sims(replace=True)\n","model_path = \"movies_alice.bin\"\n","\n","print(\"Saving model...\")\n","model_en.wv.save_word2vec_format(model_path, binary=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Saving model...\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IAgKkUuVnD83"},"source":["## Оценка\n","\n","Задача обучения модели w2v - это usupervised задача (обучение без учителя), \"правильных\" ответов нет, поэтому нельзя вычислить некую метрику качества, чтобы сравнить две модели между собой или просто по значению одной метрики сказать, насколько хороша полученная модель. \n","\n","Тем не менее, существуют специальные выборки для оценки качества дистрибутивных моделей. Основных два: один измеряет точность решения задач на аналогии (пример про Россию и пельмени), а второй используется для оценки коэффициента семантической близости. "]},{"cell_type":"markdown","metadata":{"id":"VTpG9KjE9eUQ"},"source":["### Аналогии\n","\n","Другая популярная задача для \"внутренней\" оценки называется задачей поиска аналогий. Как мы уже разбирали выше, с помощью простых арифметических операций мы можем модифицировать значение слова. Если заранее собрать набор слов-модификаторов, а также слов, которые мы хотим получить в результаты модификации, то на основе подсчёта количества \"попаданий\" в желаемое слово мы можем оценить, насколько хорошо работает модель.\n","\n","В качестве слов-модификаторов мы можем использовать семантические аналогии. Скажем, если у нас есть некоторое отношение \"страна-столица\", то для оценки модели мы можем использовать пары наподобие \"Россия-Москва\", \"Норвегия-Осло\", и т.д. Выборка будет выглядеть следующм образом:\n","\n","| слово 1    | слово 2    | отношение     | \n","|------------|------------|---------------|\n","| Россия     | Москва     | страна-столица|  \n","| Норвегия   | Осло       | страна-столица|\n","\n","Рассматривая случайные две пары из этого набора, мы хотим, имея триплет (Россия, Москва, Норвегия), получить слово \"Осло\", т.е. найти такое слово, которое будет находиться в том же отношении со словом \"Норвегия\", как \"Россия\" находится с Москвой. \n","\n","Выборки для русского языка можно скачать на странице с моделями на RusVectores. Посчитаем качество нашей модели НКРЯ на выборке про аналогии:"]},{"cell_type":"code","metadata":{"id":"FxRUo3g_9hw0"},"source":["! wget https://raw.githubusercontent.com/ancatmara/data-science-nlp/master/data/w2v/evaluation/ru_analogy_tagged.txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yUJHg-6v9lF6"},"source":["with open('ru_analogy_tagged.txt','r') as f:\n","  data = f.readlines()\n","  print (data[:10])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lAHA6zn09lrP"},"source":["res = model_ru.accuracy('ru_analogy_tagged.txt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bdf-h9Uf9r5N"},"source":["print(res[4]['incorrect'][:10])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pBJ0_n2e9yct"},"source":["### Word Similarity\n","\n","Этот метод заключается в том, чтобы оценить, насколько представления о семантической близости слов в модели соотносятся с \"представлениями\" людей.\n","\n","| слово 1    | слово 2    | близость | \n","|------------|------------|----------|\n","| кошка      | собака     | 0.7      |  \n","| чашка      | кружка     | 0.9      |       \n","\n","Для каждой пары слов из заранее заданного датасета мы можем посчитать косинусное расстояние, и получить список таких значений близости. При этом у нас уже есть список значений близостей, сделанный людьми. Мы можем сравнить эти два списка и понять, насколько они похожи (например, посчитав корреляцию). Эта мера схожести должна говорить о том, насколько модель хорошо моделирует расстояния до слова.\n"]},{"cell_type":"markdown","metadata":{"id":"AsnuE_CgnJO3"},"source":["## Бонус 3. FastText\n","\n","FastText использует не только эмбеддинги слов, но и эмбеддинги n-грам. В корпусе каждое слово автоматически представляется в виде набора символьных n-грамм. \n","\n","Скажем, если мы установим n=3, то вектор для слова \"where\" будет представлен суммой векторов следующих триграм: \"<wh\", \"whe\", \"her\", \"ere\", \"re>\" (где \"<\" и \">\" символы, обозначающие начало и конец слова). \n","\n","Благодаря этому мы можем также получать вектора для слов, отсутствуюших в словаре, а также эффективно работать с текстами, содержащими ошибки и опечатки.\n","\n","* [Статья](https://aclweb.org/anthology/Q17-1010)\n","* [Сайт](https://fasttext.cc/)\n","* [Тьюториал](https://fasttext.cc/docs/en/support.html)\n","* [Вектора для 157 языков](https://fasttext.cc/docs/en/crawl-vectors.html)\n","* [Вектора, обученные на википедии](https://fasttext.cc/docs/en/pretrained-vectors.html) (отдельно для 294 разных языков)\n","* [Репозиторий](https://github.com/facebookresearch/fasttext)\n","\n","Есть библиотека `fasttext` для питона (с готовыми моделями можно работать и через `gensim`)."]},{"cell_type":"code","metadata":{"id":"-UXvgavDnLlx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604734258552,"user_tz":-180,"elapsed":48287,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"7e9c28d4-f743-47b7-db6d-ecade37aab58"},"source":["# чтобы установить fasstext, можно склонировать его с репозитория \n","! git clone https://github.com/facebookresearch/fastText.git\n","! pip3 install fastText/."],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'fastText'...\n","remote: Enumerating objects: 3854, done.\u001b[K\n","remote: Total 3854 (delta 0), reused 0 (delta 0), pack-reused 3854\u001b[K\n","Receiving objects: 100% (3854/3854), 8.22 MiB | 33.16 MiB/s, done.\n","Resolving deltas: 100% (2417/2417), done.\n","Processing ./fastText\n","Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.2) (2.6.0)\n","Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.2) (50.3.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.2) (1.18.5)\n","Building wheels for collected packages: fasttext\n","  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fasttext: filename=fasttext-0.9.2-cp36-cp36m-linux_x86_64.whl size=3015942 sha256=c15164321c84a239ec4e0c4964b1f90d43fc819f037f9ef2bf4fe350286b2c54\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-755y22wk/wheels/a1/9f/52/696ce6c5c46325e840c76614ee5051458c0df10306987e7443\n","Successfully built fasttext\n","Installing collected packages: fasttext\n","Successfully installed fasttext-0.9.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GerzfRvLnQfC"},"source":["import fasttext\n","\n","ft_model = fasttext.train_unsupervised('clean_text.txt', minn=3, maxn=4, dim=300)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fL0w3IrUnTr_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604734282034,"user_tz":-180,"elapsed":18562,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"89fda736-a756-4e7b-8f99-b30200abe0f7"},"source":["ft_model.get_nearest_neighbors('actor')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0.9999606013298035, 'actors'),\n"," (0.9999364018440247, 'attractive'),\n"," (0.9999338984489441, 'fact'),\n"," (0.9999316334724426, 'actual'),\n"," (0.9999226331710815, 'display'),\n"," (0.9999191761016846, 'terrific'),\n"," (0.9999188780784607, 'battle'),\n"," (0.9999170899391174, 'israel'),\n"," (0.9999163746833801, 'british'),\n"," (0.9999160170555115, 'predator')]"]},"metadata":{"tags":[]},"execution_count":183}]},{"cell_type":"code","metadata":{"id":"Akwp4geNnWMh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604734282036,"user_tz":-180,"elapsed":17685,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"829bf23f-a57c-4703-efde-f27eff5d1635"},"source":["ft_model.get_analogies(\"woman\", \"man\", \"actor\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0.999938428401947, 'act'),\n"," (0.9998956918716431, 'exactly'),\n"," (0.9998955726623535, 'actress'),\n"," (0.999885082244873, 'seemingly'),\n"," (0.9998830556869507, 'terrible'),\n"," (0.9998824596405029, 'surprisingly'),\n"," (0.9998821020126343, 'believable'),\n"," (0.9998811483383179, 'double'),\n"," (0.9998807907104492, 'written'),\n"," (0.9998795986175537, 'cable')]"]},"metadata":{"tags":[]},"execution_count":184}]},{"cell_type":"code","metadata":{"id":"J_yBTNiTnbQj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604734282038,"user_tz":-180,"elapsed":10494,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"5e493dc4-610d-4ae7-fe6a-d30beb494365"},"source":["ft_model.get_nearest_neighbors('actr')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0.9999391436576843, 'act'),\n"," (0.9998903274536133, 'actors'),\n"," (0.9998863339424133, 'actor'),\n"," (0.9998792409896851, 'actress'),\n"," (0.9998623728752136, 'single'),\n"," (0.9998517632484436, 'actual'),\n"," (0.9998226761817932, 'terrible'),\n"," (0.9998196363449097, 'exact'),\n"," (0.9998190402984619, 'plot'),\n"," (0.9998172521591187, 'wrong')]"]},"metadata":{"tags":[]},"execution_count":185}]},{"cell_type":"code","metadata":{"id":"lyk-qki4njoE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604734390476,"user_tz":-180,"elapsed":774,"user":{"displayName":"Maksim Khlopotov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjrfi2fUKbxZsEmFSi6eHxb-YT0aNnTzgBjBm83jg=s64","userId":"17573813484649782255"}},"outputId":"8dcb1e2a-fcfe-471b-cb02-08f5a0f710cd"},"source":["ft_model.get_nearest_neighbors('moviegeek')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0.9999324679374695, 'reviews'),\n"," (0.9999246597290039, 'review'),\n"," (0.9999151825904846, 'recommended'),\n"," (0.9999132752418518, 'rented'),\n"," (0.9998916387557983, 'waste'),\n"," (0.999889075756073, 'movie'),\n"," (0.9998835921287537, 'thank'),\n"," (0.9998812079429626, 'not'),\n"," (0.9998751878738403, 'watchable'),\n"," (0.9998645782470703, 'only')]"]},"metadata":{"tags":[]},"execution_count":187}]},{"cell_type":"markdown","metadata":{"id":"igRgYdQFzU62"},"source":["Дополнение: https://github.com/dipanjanS/text-analytics-with-python/tree/master/New-Second-Edition"]}]}